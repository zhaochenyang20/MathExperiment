# 1

```python
import numpy as np
from scipy.optimize import linprog

# Define the objective function
c = np.array([-64, -54])

# Define the inequality constraints
A_ub = np.array([[3, 0], [12, 8]])
b_ub = np.array([80, 480])

# Define the equality constraints
A_eq = np.array([[1, 1]])
b_eq = np.array([55])

# Define the bounds
bounds = [(0, 55), (0, 55)]

# Call the linprog function
res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)

print(res)

------

        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)
        success: True
         status: 0
            fun: -3070.0
              x: [ 1.000e+01  4.500e+01]
            nit: 0
          lower:  residual: [ 1.000e+01  4.500e+01]
                 marginals: [ 0.000e+00  0.000e+00]
          upper:  residual: [ 4.500e+01  1.000e+01]
                 marginals: [ 0.000e+00  0.000e+00]
          eqlin:  residual: [ 0.000e+00]
                 marginals: [-3.400e+01]
        ineqlin:  residual: [ 5.000e+01  0.000e+00]
                 marginals: [-0.000e+00 -2.500e+00]
```

1. 模型：

$3x_1\leq80,x_1+x_2=55,12x_1+8x_2<=480$，求 $64x+54y$ 的 max。

2. 3070，加班费 2.50：注意看 ineqlin 的 marginals，意味着不等条件每增加 1，fun 增加 2.5，也即每多 1 小时工时，收益多 2.5，算作加班费。

3. 不改变，代码如下：

```python
import numpy as np
from scipy.optimize import linprog

# Define the objective function
c = np.array([-78, -54])

# Define the inequality constraints
A_ub = np.array([[3, 0], [12, 8]])
b_ub = np.array([80, 480])

# Define the equality constraints
A_eq = np.array([[1, 1]])
b_eq = np.array([55])

# Define the bounds
bounds = [(0, 55), (0, 55)]

# Call the linprog function
res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)

print(res)
```

# 2

$x^2 y^{\prime \prime}+x y^{\prime}+\left(x^2-\frac{1}{4}\right) y=0, \quad y\left(\frac{\pi}{2}\right)=2, \quad y^{\prime}\left(\frac{\pi}{2}\right)=-\frac{2}{\pi}$

试用数值方法求 $y\left(\frac{\pi}{6}\right)=$ (保留小数点后 5 位数字)

首先，将二阶微分方程转化为一组一阶微分方程：

$$
\begin{aligned}
& \frac{dy}{dx} =t \\
& \frac{dt}{dx} =-\frac{xt +\left(x^{2}-\frac{1}{4}\right) y}{x^{2}}
\end{aligned}
$$

```python
import numpy as np
from scipy.integrate import odeint

def dyt_dx(input_list, x):
		y, t = input_list
    return [t, -(x * t + (x ** 2 - 1/4) * y) / (x ** 2)]

# 初始条件
y_a = [2, -2/np.pi]

# 自变量范围
x = np.linspace(np.pi/2, np.pi/6, 100)

# 求解微分方程
y = odeint(f, y_a, x)

# 输出结果
print(round(y[-1, 0], 5))
```

1.73205

# 3

```python
import numpy as np

b = np.array([6, 3, 4, 7])
A = np.array([[5, -7, 0, 1],
             [-3, 22, 6, 2],
             [5, -1, 31, -1],
             [2, 1, 0, 23]])

delta = np.array([0, 0, 0, 0.1])
norm_b = np.linalg.norm(b, 1)
cond_arr = np.linalg.cond(A, 1)
norm_delta = np.linalg.norm(delta, 1)
print(cond_arr * norm_delta / norm_b)
```

误差：0.07433906520893041

```py
import numpy as np

def split_matrix(A):
    n = A.shape[0]  # 方阵的维度
    D = np.diag(np.diag(A))  # 对角矩阵
    L = -np.tril(A, k=-1)  # 严格下三角矩阵
    U = -np.triu(A, k=1)  # 严格上三角矩阵
    return D, L, U


def jacobi(A, x0, b, error=1e-6):
    D, L, U = split_matrix(A)
    inv_D = np.linalg.inv(D)
    k = 0
    xk = x0
    while True:
        k += 1
        xk_1 = inv_D @ ((L + U) @ xk + b)
        step = np.linalg.norm(xk - xk_1, np.inf)
        xk = xk_1
        print("--------------------")
        print(f"迭代次数：{k}")
        print(f"迭代结果：{xk}")
        print(f"step {step}")
        if step < error:
            return xk_1, k


def gauss_seidel(A, x0, b, error=1e-6):
    D, L, U = split_matrix(A)
    inv_D_minus_L = np.linalg.inv(D - L)
    k = 0
    xk = x0
    while True:
        k += 1
        xk_1 = inv_D_minus_L @ (U @ xk + b)
        step = np.linalg.norm(xk - xk_1, np.inf)
        xk = xk_1
        print("--------------------")
        print(f"迭代次数：{k}")
        print(f"迭代结果：{xk}")
        print(f"step {step}")
        if step < error:
            return xk_1, k

b = np.array([6, 3, 4, 7])
A = np.array([[5, -7, 0, 1],
             [-3, 22, 6, 2],
             [5, -1, 31, -1],
             [2, 1, 0, 23]])

x0 = np.array([0, 0, 0, 0])

x, k = gauss_seidel(A, x0, b)
x, k = jacobi(A, x0, b)
```

```py
5
[ 1.71597235  0.39264682 -0.1305711   0.13806124]
step 0.014587358828084485
```

收敛，迭代矩阵谱半径为 0.4 < 1。

```python
import numpy as np

def split_matrix(A):
    n = A.shape[0]  # 方阵的维度
    D = np.diag(np.diag(A))  # 对角矩阵
    L = -np.tril(A, k=-1)  # 严格下三角矩阵
    U = -np.triu(A, k=1)  # 严格上三角矩阵
    return D, L, U

def spectral_radius(matrix):
    eigenvalues = np.linalg.eigvals(matrix)
    radius = np.max(np.abs(eigenvalues))
    return radius

A = np.array([[5, -7, 0, 1],
             [-3, 22, 6, 2],
             [5, -1, 31, -1],
             [2, 1, 0, 23]])
D, L, U = split_matrix(A)
inv_D_minus_L = np.linalg.inv(D - L)
step_matrix = inv_D_minus_L @ U
print(spectral_radius(step_matrix))
```

# 4

## 4.1 假设检验

```python
def t_test(data_list, confidence_level, mu_0=None, test_method="double"):
    print("用于在方差未知的情况下估计均值或者对均值进行检验")
    assert test_method in ["left", "right", "double"]
    from scipy.stats import t
    import numpy as np
    n = len(data_list)
    sample_mean = np.mean(data_list)
    sample_std = np.std(data_list, ddof=1)
    center = mu_0 if mu_0 else sample_mean
    #! 假设检验需要传入假设的 mu_0，区间估计本身就是为了估计 mu_0，不用 mu_0
    if mu_0 != None:
        print("正在进行假设检验")
        t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))
    #! t_statistic 仅在计算 p 的时候使用，p 表示在 mu_0 正确时，sample_mean 比起当前更异常的概率
    if test_method == "double":
        #! alpha = 1 - confidence_level，故而 1 + confidence_level) / 2 = 1- alpha / 2
        t_value = t.ppf((1 + confidence_level) / 2, df=n - 1)
    else:
        t_value = t.ppf(confidence_level, df=n - 1)
    margin_error = t_value * sample_std / np.sqrt(n)
    lower_bound = center - margin_error
    upper_bound = center + margin_error
    if test_method == "double":
        #! 决定是否接受假设的时候，可以直接用 sample_mean 和 bound 比较，也可以用 t_statistic 和统计量（比如 u_{1- alpha / 2}）作对比
        print(f"Confidence Interval[{confidence_level}]:", lower_bound, "-", upper_bound)
        if mu_0 != None:
        #! p 和 confidence_level / alpha 没有任何关系，只有假设检验有 p 这个概念
            p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df=n - 1))
    elif test_method == "right":
        #! 样本均值大于 right_bound 则拒绝假设
        print(f"Confidence Interval[{confidence_level}]:", "right_bound ", upper_bound)
        if mu_0 != None:
            p_value = 1 - t.cdf(t_statistic, df=n - 1)
    elif test_method == "left":
        #! 样本均值小于 left_bound 则拒绝假设
        print(f"Confidence Interval[{confidence_level}]:", "left_bound", lower_bound)
        if mu_0 != None:
            p_value = t.cdf(t_statistic, df=n - 1)
    if mu_0 != None:
        print(f"P-value: {p_value}")
        return p_value

def z_test(data_list, confidence_level, sigma, mu_0=None, test_method="double"):
    print("用于在方差已知的情况下估计均值或者对均值进行检验")
    print(f"sigma 目前是 {sigma}，这里需要传入标准差，而不是方差")
    print(f"mu_0: {mu_0}")
    assert test_method in ["left", "right", "double"]
    from scipy.stats import norm
    import numpy as np
    n = len(data_list)
    sample_mean = np.mean(data_list)
    center = mu_0 if mu_0 else sample_mean
    if mu_0 != None:
        print("正在进行假设检验")
        z_statistic = (sample_mean - mu_0) / (sigma / np.sqrt(n))
    if test_method == "double":
        z_value = norm.ppf((1 + confidence_level) / 2)
    else:
        z_value = norm.ppf(confidence_level)
    margin_error = z_value * sigma / np.sqrt(n)
    lower_bound = center - margin_error
    upper_bound = center + margin_error
    if test_method == "double":
        print(f"Confidence Interval[{confidence_level}]:", lower_bound, "-", upper_bound)
        if mu_0 != None:
            p_value = 2 * (1 - norm.cdf(np.abs(z_statistic)))
    elif test_method == "right":
        print(f"Confidence Interval[{confidence_level}]:", "right_bound ", upper_bound)
        if mu_0 != None:
            p_value = 1 - norm.cdf(z_statistic)
    elif test_method == "left":
        print(f"Confidence Interval[{confidence_level}]:", "left_bound", lower_bound)
        if mu_0 != None:
            p_value = norm.cdf(z_statistic)
    if mu_0 != None:
        print(f"P-value: {p_value}")
        return p_value

def chi_test(data_list, confidence_level, sigma_squre=None, test_method="double"):
    print("用于对方差进行区间估计或者对方差进行检验")
    print(f"sigma_squre 目前是 {sigma_squre}，这里需要传入方差，而不是标准差/均方差")
    assert test_method in ["left", "right", "double"]
    from scipy.stats import chi2
    import numpy as np
    n = len(data_list)
    sample_var = np.var(data_list, ddof=1)
    center = sigma_squre if sigma_squre else sample_var
    if sigma_squre != None:
        print("正在进行假设检验")
        chi_statistic = (n - 1) * sample_var / center
    if test_method == "double":
        chi_value1 = chi2.ppf((1 - confidence_level) / 2, df=n - 1)
        chi_value2 = chi2.ppf((1 + confidence_level) / 2, df=n - 1)
    else:
        chi_value1 = chi2.ppf((1 - confidence_level), df=n - 1)
        chi_value2 = chi2.ppf(confidence_level, df=n - 1)
    lower_bound = (n - 1) * center / chi_value2
    upper_bound = (n - 1) * center / chi_value1
    if test_method == "double":
        print(f"Confidence Interval[{confidence_level}]:", lower_bound, "-", upper_bound)
        if sigma_squre != None:
            p_value = 2 * min(chi2.cdf(chi_statistic, df=n - 1), 1 - chi2.cdf(chi_statistic, df=n - 1))
    elif test_method == "right":
        print(f"Confidence Interval[{confidence_level}]:", "right_bound ", upper_bound)
        if sigma_squre != None:
            p_value = 1 - chi2.cdf(chi_statistic, df=n - 1)
    elif test_method == "left":
        print(f"Confidence Interval[{confidence_level}]:", "left_bound", lower_bound)
        if sigma_squre != None:
            p_value = chi2.cdf(chi_statistic, df=n - 1)
    if sigma_squre != None:
        print(f"P-value: {p_value}")
        return p_value

data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,
          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]

data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,
          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]

z_test(data_X, 0.95, 70, 0)
z_test(data_Y, 0.95, 50, 0)
chi_test(data_X, 0.95, 70**2)
chi_test(data_Y, 0.95, 50**2)
```

## 4.2

```python
import numpy as np
from scipy.stats import pearsonr

data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9, 100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]

data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2, -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]

# 计算相关系数
corr_coef, p_value = pearsonr(data_X, data_Y)

# 打印相关系数和p值
print("相关系数:", corr_coef)
print("p值:", p_value)
```

## 4.3

```python
import numpy as np
from scipy.integrate import dblquad
from scipy.stats import multivariate_normal, pearsonr

def random_points(num_samples, mean, cov_matrix, a: float, b: float):
    """随机投点法"""
    # 投点
    random_points = np.random.multivariate_normal(mean, cov_matrix, num_samples)
    # 计算概率
    probability_point = (
        np.count_nonzero(
            random_points[:, 0] ** 2 / (a ** 2) + random_points[:, 1] ** 2 / (b ** 2) <= 1
        )
        / num_samples
    )
    return probability_point

def mean_estimate(num_samples: int, mean, cov_matrix, a: float, b: float) -> float:
    """均值估计法"""
    uniform_samples = np.random.uniform(
        low=[-a, -b],
        high=[a, b],
        size=(num_samples, 2),
    )
    pdf = multivariate_normal.pdf(uniform_samples, mean=mean, cov=cov_matrix)
    in_domain = np.where(
        uniform_samples[:, 0] ** 2 / (a ** 2) + uniform_samples[:, 1] ** 2 / (b ** 2) <= 1
    )[0]
    probability_mean = (4 * a * b) * np.sum(pdf[in_domain]) / num_samples
    #! 回顾一维期望法，平均高度 * 区间长度就是区间的积分（曲线下的面积）
    #! 对于二维期望法，椭圆的面积乘以平均高度就是平面的积分（曲面下的体积）
    #! 椭圆面积可以用蒙特卡洛（长方形面积 * 椭圆内点的个数 / 总共的点数），然后平均高度就是求和后除以椭圆内点的个数
    return probability_mean

data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,
          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]
data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,
          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]
corr, p_corr = pearsonr(data_X, data_Y)
print(corr, p_corr)
num_samples = 10000
mean = [0, 0]
sigma_x = 70
sigma_y = 50
cov_matrix = [[sigma_x ** 2, corr * sigma_x * sigma_y],
              [corr * sigma_x * sigma_y, sigma_y ** 2]]
a = 110
b = 90
print(random_points(num_samples, mean, cov_matrix, a, b))
print(mean_estimate(num_samples, mean, cov_matrix, a, b))
```

