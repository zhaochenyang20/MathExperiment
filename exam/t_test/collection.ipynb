{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [  0.           1.04274366 -15.25556929]\n",
      "        2\n",
      "-8.671 x + 9.713 x\n"
     ]
    }
   ],
   "source": [
    "## 拉格朗日多项式插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import lagrange\n",
    "\n",
    "# 插值节点的x坐标和对应的y坐标\n",
    "func = lambda x: np.exp(2 * x) * np.sin(3 * x)\n",
    "\n",
    "x = np.array([0, 1, 2])\n",
    "y = func(x)\n",
    "\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "# 计算拉格朗日插值多项式\n",
    "poly = lagrange(x, y)\n",
    "\n",
    "# 输出多项式系数\n",
    "print(poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb Cell 3\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m \u001b[39mimport\u001b[39;00m Symbol, exp, sin\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolys\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolyfuncs\u001b[39;00m \u001b[39mimport\u001b[39;00m interpolate\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 定义插值节点\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/__init__.py:74\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogic\u001b[39;00m \u001b[39mimport\u001b[39;00m (to_cnf, to_dnf, to_nnf, And, Or, Not, Xor, Nand, Nor,\n\u001b[1;32m     68\u001b[0m         Implies, Equivalent, ITE, POSform, SOPform, simplify_logic, bool_map,\n\u001b[1;32m     69\u001b[0m         true, false, satisfiable)\n\u001b[1;32m     71\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39massumptions\u001b[39;00m \u001b[39mimport\u001b[39;00m (AppliedPredicate, Predicate, AssumptionsContext,\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolys\u001b[39;00m \u001b[39mimport\u001b[39;00m (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[1;32m     75\u001b[0m         degree, total_degree, degree_list, LC, LM, LT, pdiv, prem, pquo,\n\u001b[1;32m     76\u001b[0m         pexquo, div, rem, quo, exquo, half_gcdex, gcdex, invert,\n\u001b[1;32m     77\u001b[0m         subresultants, resultant, discriminant, cofactors, gcd_list, gcd,\n\u001b[1;32m     78\u001b[0m         lcm_list, lcm, terms_gcd, trunc, monic, content, primitive, compose,\n\u001b[1;32m     79\u001b[0m         decompose, sturm, gff_list, gff, sqf_norm, sqf_part, sqf_list, sqf,\n\u001b[1;32m     80\u001b[0m         factor_list, factor, intervals, refine_root, count_roots, real_roots,\n\u001b[1;32m     81\u001b[0m         nroots, ground_roots, nth_power_roots_poly, cancel, reduced, groebner,\n\u001b[1;32m     82\u001b[0m         is_zero_dimensional, GroebnerBasis, poly, symmetrize, horner,\n\u001b[1;32m     83\u001b[0m         interpolate, rational_interpolate, viete, together,\n\u001b[1;32m     84\u001b[0m         BasePolynomialError, ExactQuotientFailed, PolynomialDivisionFailed,\n\u001b[1;32m     85\u001b[0m         OperationNotSupported, HeuristicGCDFailed, HomomorphismFailed,\n\u001b[1;32m     86\u001b[0m         IsomorphismFailed, ExtraneousFactors, EvaluationFailed,\n\u001b[1;32m     87\u001b[0m         RefinementFailed, CoercionFailed, NotInvertible, NotReversible,\n\u001b[1;32m     88\u001b[0m         NotAlgebraic, DomainError, PolynomialError, UnificationFailed,\n\u001b[1;32m     89\u001b[0m         GeneratorsError, GeneratorsNeeded, ComputationFailed,\n\u001b[1;32m     90\u001b[0m         UnivariatePolynomialError, MultivariatePolynomialError,\n\u001b[1;32m     91\u001b[0m         PolificationFailed, OptionError, FlagError, minpoly,\n\u001b[1;32m     92\u001b[0m         minimal_polynomial, primitive_element, field_isomorphism,\n\u001b[1;32m     93\u001b[0m         to_number_field, isolate, round_two, prime_decomp, prime_valuation,\n\u001b[1;32m     94\u001b[0m         galois_group, itermonomials, Monomial, lex, grlex,\n\u001b[1;32m     95\u001b[0m         grevlex, ilex, igrlex, igrevlex, CRootOf, rootof, RootOf,\n\u001b[1;32m     96\u001b[0m         ComplexRootOf, RootSum, roots, Domain, FiniteField, IntegerRing,\n\u001b[1;32m     97\u001b[0m         RationalField, RealField, ComplexField, PythonFiniteField,\n\u001b[1;32m     98\u001b[0m         GMPYFiniteField, PythonIntegerRing, GMPYIntegerRing, PythonRational,\n\u001b[1;32m     99\u001b[0m         GMPYRationalField, AlgebraicField, PolynomialRing, FractionField,\n\u001b[1;32m    100\u001b[0m         ExpressionDomain, FF_python, FF_gmpy, ZZ_python, ZZ_gmpy, QQ_python,\n\u001b[1;32m    101\u001b[0m         QQ_gmpy, GF, FF, ZZ, QQ, ZZ_I, QQ_I, RR, CC, EX, EXRAW,\n\u001b[1;32m    102\u001b[0m         construct_domain, swinnerton_dyer_poly, cyclotomic_poly,\n\u001b[1;32m    103\u001b[0m         symmetric_poly, random_poly, interpolating_poly, jacobi_poly,\n\u001b[1;32m    104\u001b[0m         chebyshevt_poly, chebyshevu_poly, hermite_poly, hermite_prob_poly,\n\u001b[1;32m    105\u001b[0m         legendre_poly, laguerre_poly, apart, apart_list, assemble_partfrac_list,\n\u001b[1;32m    106\u001b[0m         Options, ring, xring, vring, sring, field, xfield, vfield, sfield)\n\u001b[1;32m    108\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m (Order, O, limit, Limit, gruntz, series, approximants,\n\u001b[1;32m    109\u001b[0m         residue, EmptySequence, SeqPer, SeqFormula, sequence, SeqAdd, SeqMul,\n\u001b[1;32m    110\u001b[0m         fourier_series, fps, difference_delta, limit_seq)\n\u001b[1;32m    112\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m (factorial, factorial2, rf, ff, binomial,\n\u001b[1;32m    113\u001b[0m         RisingFactorial, FallingFactorial, subfactorial, carmichael,\n\u001b[1;32m    114\u001b[0m         fibonacci, lucas, motzkin, tribonacci, harmonic, bernoulli, bell, euler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         Znm, elliptic_k, elliptic_f, elliptic_e, elliptic_pi, beta, mathieus,\n\u001b[1;32m    134\u001b[0m         mathieuc, mathieusprime, mathieucprime, riemann_xi, betainc, betainc_regularized)\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/polys/__init__.py:123\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39morthopolys\u001b[39;00m \u001b[39mimport\u001b[39;00m (jacobi_poly, chebyshevt_poly, chebyshevu_poly,\n\u001b[1;32m    118\u001b[0m         hermite_poly, hermite_prob_poly, legendre_poly, laguerre_poly)\n\u001b[1;32m    120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mappellseqs\u001b[39;00m \u001b[39mimport\u001b[39;00m (bernoulli_poly, bernoulli_c_poly, genocchi_poly,\n\u001b[1;32m    121\u001b[0m         euler_poly, andre_poly)\n\u001b[0;32m--> 123\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpartfrac\u001b[39;00m \u001b[39mimport\u001b[39;00m apart, apart_list, assemble_partfrac_list\n\u001b[1;32m    125\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolyoptions\u001b[39;00m \u001b[39mimport\u001b[39;00m Options\n\u001b[1;32m    127\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrings\u001b[39;00m \u001b[39mimport\u001b[39;00m ring, xring, vring, sring\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/polys/partfrac.py:15\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolys\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolytools\u001b[39;00m \u001b[39mimport\u001b[39;00m parallel_poly_from_expr\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m numbered_symbols, take, xthreaded, public\n\u001b[1;32m     13\u001b[0m \u001b[39m@xthreaded\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[39m@public\u001b[39;49m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mapart\u001b[39;49m(f, x\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, full\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions):\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    Compute partial fraction decomposition of a rational function.\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m    apart_list, assemble_partfrac_list\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     allowed_flags(options, [])\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/utilities/decorator.py:76\u001b[0m, in \u001b[0;36mxthreaded\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mxthreaded\u001b[39m(func):\n\u001b[1;32m     60\u001b[0m     \u001b[39m\"\"\"Apply ``func`` to sub--elements of an object, excluding :class:`~.Add`.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This decorator is intended to make it uniformly possible to apply a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m threaded_factory(func, \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/utilities/decorator.py:13\u001b[0m, in \u001b[0;36mthreaded_factory\u001b[0;34m(func, use_add)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m\"\"\"A factory for ``threaded`` decorators. \"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m sympify\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmatrices\u001b[39;00m \u001b[39mimport\u001b[39;00m MatrixBase\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msympy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miterables\u001b[39;00m \u001b[39mimport\u001b[39;00m iterable\n\u001b[1;32m     16\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthreaded_func\u001b[39m(expr, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/anaconda3/envs/da/lib/python3.10/site-packages/sympy/matrices/__init__.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m MutableSparseMatrix\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msparsetools\u001b[39;00m \u001b[39mimport\u001b[39;00m banded\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimmutable\u001b[39;00m \u001b[39mimport\u001b[39;00m ImmutableDenseMatrix, ImmutableSparseMatrix\n\u001b[1;32m     23\u001b[0m ImmutableMatrix \u001b[39m=\u001b[39m ImmutableDenseMatrix\n\u001b[1;32m     24\u001b[0m SparseMatrix \u001b[39m=\u001b[39m MutableSparseMatrix\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1012\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:672\u001b[0m, in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sympy import Symbol, exp, sin\n",
    "from sympy.polys.polyfuncs import interpolate\n",
    "\n",
    "# 定义插值节点\n",
    "x_values = [0, 1, 2]\n",
    "\n",
    "# 定义函数\n",
    "x = Symbol('x')\n",
    "f = exp(2*x) * sin(3*x)\n",
    "\n",
    "# 计算 Lagrange 插值多项式\n",
    "lagrange_poly = interpolate(x_values, [f.subs(x, xi) for xi in x_values])\n",
    "\n",
    "# 获取高精度的系数\n",
    "coefficients = lagrange_poly.all_coeffs()\n",
    "\n",
    "# 输出多项式系数\n",
    "print(coefficients)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数值积分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯形公式&Simpson 公式（大步长时注意包含右端点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " simpson(y, x=None, dx=1.0, axis=-1, even='avg')\n",
      "\n",
      "Integrate y(x) using samples along the given axis and the composite\n",
      "Simpson's rule. If x is None, spacing of dx is assumed.\n",
      "\n",
      "If there are an even number of samples, N, then there are an odd\n",
      "number of intervals (N-1), but Simpson's rule requires an even number\n",
      "of intervals. The parameter 'even' controls how this is handled.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "y : array_like\n",
      "    Array to be integrated.\n",
      "x : array_like, optional\n",
      "    If given, the points at which `y` is sampled.\n",
      "dx : float, optional\n",
      "    Spacing of integration points along axis of `x`. Only used when\n",
      "    `x` is None. Default is 1.\n",
      "axis : int, optional\n",
      "    Axis along which to integrate. Default is the last axis.\n",
      "even : str {'avg', 'first', 'last'}, optional\n",
      "    'avg' : Average two results:1) use the first N-2 intervals with\n",
      "              a trapezoidal rule on the last interval and 2) use the last\n",
      "              N-2 intervals with a trapezoidal rule on the first interval.\n",
      "\n",
      "    'first' : Use Simpson's rule for the first N-2 intervals with\n",
      "            a trapezoidal rule on the last interval.\n",
      "\n",
      "    'last' : Use Simpson's rule for the last N-2 intervals with a\n",
      "           trapezoidal rule on the first interval.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "float\n",
      "    The estimated integral computed with the composite Simpson's rule.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "quad : adaptive quadrature using QUADPACK\n",
      "romberg : adaptive Romberg quadrature\n",
      "quadrature : adaptive Gaussian quadrature\n",
      "fixed_quad : fixed-order Gaussian quadrature\n",
      "dblquad : double integrals\n",
      "tplquad : triple integrals\n",
      "romb : integrators for sampled data\n",
      "cumulative_trapezoid : cumulative integration for sampled data\n",
      "ode : ODE integrators\n",
      "odeint : ODE integrators\n",
      "\n",
      "Notes\n",
      "-----\n",
      "For an odd number of samples that are equally spaced the result is\n",
      "exact if the function is a polynomial of order 3 or less. If\n",
      "the samples are not equally spaced, then the result is exact only\n",
      "if the function is a polynomial of order 2 or less.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from scipy import integrate\n",
      ">>> import numpy as np\n",
      ">>> x = np.arange(0, 10)\n",
      ">>> y = np.arange(0, 10)\n",
      "\n",
      ">>> integrate.simpson(y, x)\n",
      "40.5\n",
      "\n",
      ">>> y = np.power(x, 3)\n",
      ">>> integrate.simpson(y, x)\n",
      "1642.5\n",
      ">>> integrate.quad(lambda x: x**3, 0, 9)[0]\n",
      "1640.25\n",
      "\n",
      ">>> integrate.simpson(y, x, even='first')\n",
      "1644.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_722/3339673506.py:2: DeprecationWarning: scipy.info is deprecated and will be removed in SciPy 2.0.0, use numpy.info instead\n",
      "  scipy.info(scipy.integrate.simpson)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.info(scipy.integrate.simpson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precise integral  : 6.247691871606495\n",
      "integral interval : [0, 6.283185307179586] (step=1.5707963267948966)\n",
      "trapezoid formula :6.247641317417333\n",
      "Simpson formula   :6.247691871606496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4649/439458796.py:23: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  precise_integral = integrate.quad(func, start, stop, epsabs=abs_err, epsrel=rel_err, )[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import integrate\n",
    "\n",
    "# 被积函数\n",
    "func = lambda theta: np.sqrt(1 - 0.15**2 * (np.sin(theta)**2))\n",
    "\n",
    "# # 指定采样点数目\n",
    "# for i in range(3,7): \n",
    "#     n = 10 ** i\n",
    "#     xs = np.linspace(0.0, 1.0, n)\n",
    "#     ys = func(xs)\n",
    "#     integral_by_trapezoid = integrate.trapezoid(ys,xs) # 梯形公式\n",
    "#     integral_by_simpson = integrate.simpson(ys,xs) # 辛普森公式\n",
    "\n",
    "#     print(f\"trapezoid formula :{integral_by_trapezoid:.15f} (n={n})\")\n",
    "#     print(f\"Simpson formula   :{integral_by_simpson:.15f} (n={n})\")\n",
    "\n",
    "# 指定步长\n",
    "\n",
    "def step_integral(func, start, stop, step, abs_err = 1e-15, rel_err = 1e-15):\n",
    "    xs = np.arange(start, stop + 0.1 * step, step)\n",
    "    ys = func(xs)\n",
    "    precise_integral = integrate.quad(func, start, stop, epsabs=abs_err, epsrel=rel_err, )[0]\n",
    "    integral_by_trapezoid = integrate.trapezoid(ys,xs) # 梯形公式\n",
    "    \n",
    "    xs = np.linspace(start, stop, 100000)\n",
    "    ys = func(xs)\n",
    "    integral_by_simpson = integrate.simpson(ys,xs) # 辛普森公式\n",
    "    print(f\"precise integral  : {precise_integral}\")\n",
    "    print(f\"integral interval : [{start}, {stop}] (step={step})\")\n",
    "    print(f\"trapezoid formula :{integral_by_trapezoid:.15f}\")\n",
    "    print(f\"Simpson formula   :{integral_by_simpson:.15f}\")\n",
    "    \n",
    "step_integral(func, 0 ,2 * np.pi, np.pi / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数值微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 10.0, 8.0, 7.5, 6.0, 3.0, 3.0, 4.0, 3.0, 3.5, 8.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_derivative(y, h):\n",
    "    n = len(y)\n",
    "    dy = [0] * n\n",
    "\n",
    "    # 中间点的导数\n",
    "    for i in range(1, n-1):\n",
    "        dy[i] = (y[i+1] - y[i-1]) / (2 * h)\n",
    "\n",
    "    # 左端点的导数（向前差分）\n",
    "    dy[0] = (-3 * y[0] + 4 * y[1] - y[2]) / (2 * h)\n",
    "\n",
    "    # 右端点的导数（向后差分）\n",
    "    dy[n-1] = (3 * y[n-1] - 4 * y[n-2] + y[n-3]) / (2 * h)\n",
    "\n",
    "    return dy\n",
    "\n",
    "\n",
    "t = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
    "x = np.array([1070, 1270, 1480, 1700, 1910, 2140, 2360, 2600, 2830, 3070, 3310])\n",
    "v = np.array([190, 200, 210, 216, 225, 228, 231, 234, 239, 240, 246])\n",
    "\n",
    "a = calculate_derivative(v, 1)\n",
    "print(f\"a = {a}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.  10.   8.   7.5  6.   3.   3.   4.   3.   3.5  6. ]\n",
      "[0.48749859]\n",
      "用于在方差未知的情况下估计均值或者对均值进行检验\n",
      "样本均值:  0.492548210963488\n",
      "样本标准差:  0.027646129207894426\n",
      "正在进行假设检验\n",
      "正在计算双侧区间\n",
      "Confidence Interval[0.95]: 0.48243448752934703 - 0.517565512470653\n",
      "P-value: 0.3704914113930142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3704914113930142"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# 加载数据集，假设已经有了一组v(t)与t的数据\n",
    "t_data = np.arange(10, 21, 1)\n",
    "v_data = np.array([190, 200, 210, 216, 225, 228, 231, 234, 239, 240, 246])\n",
    "assert len(t_data) == len(v_data)\n",
    "a_data = np.zeros(len(t_data))\n",
    "for i in range(1, len(t_data) - 1):\n",
    "    a_data[i] = (v_data[i + 1] - v_data[i - 1]) / 2\n",
    "a_data[0] = v_data[1] - v_data[0]\n",
    "a_data[len(t_data) - 1] = v_data[len(t_data) - 1] - v_data[len(t_data) - 2]\n",
    "\n",
    "print(a_data)\n",
    "\n",
    "def objective(x):\n",
    "    #! 构造残差函数，也即 f = g(t)，则残差为 f - g(t)\n",
    "    k = x[0]\n",
    "    F = np.zeros(len(t_data))\n",
    "    for i in range(len(t_data)):\n",
    "        v = v_data[i]\n",
    "        a = a_data[i]\n",
    "        t = t_data[i]\n",
    "        m = 1200 -15 * t\n",
    "        F[i] = a - (-k * v**2 / m + 40000 / m - 9.8)\n",
    "    return F\n",
    "\n",
    "x0 = [0.5]\n",
    "#! x0 的选取影响很大，但是 tau 确实不该取 0\n",
    "res = least_squares(objective, x0)\n",
    "print(res.x)\n",
    "\n",
    "def k_func(a, t, v):\n",
    "    m = 1200 -15 * t\n",
    "    k = (40000 - 9.8 * m - a * m) / v ** 2\n",
    "    return k\n",
    "\n",
    "k_list = []\n",
    "\n",
    "for i in range(len(t_data)):\n",
    "    k = k_func(a_data[i], t_data[i], v_data[i])\n",
    "    k_list.append(k)\n",
    "\n",
    "np.mean(k_list)\n",
    "\n",
    "#! 上方采用了直接求均值法和最小二乘法\n",
    "\n",
    "k_list.append(res.x[0])\n",
    "\n",
    "\n",
    "def t_test(data_list, confidence_level, mu_0=None, test_method=\"double\"):\n",
    "    print(\"用于在方差未知的情况下估计均值或者对均值进行检验\")\n",
    "    assert test_method in [\"left\", \"right\", \"double\"]\n",
    "    from scipy.stats import t\n",
    "    import numpy as np\n",
    "    n = len(data_list)\n",
    "    sample_mean = np.mean(data_list)\n",
    "    print(\"样本均值: \", sample_mean)\n",
    "    sample_std = np.std(data_list, ddof=1)\n",
    "    print(\"样本标准差: \", sample_std)\n",
    "    center = mu_0 if mu_0 else sample_mean\n",
    "    #! 假设检验需要传入假设的 mu_0，区间估计本身就是为了估计 mu_0，不用 mu_0\n",
    "    if mu_0 != None:\n",
    "        print(\"正在进行假设检验\")\n",
    "        t_statistic = (sample_mean - mu_0) / (sample_std / np.sqrt(n))\n",
    "    else:\n",
    "        print(\"正在进行区间估计\")\n",
    "    #! t_statistic 仅在计算 p 的时候使用，p 表示在 mu_0 正确时，sample_mean 比起当前更异常的概率\n",
    "    if test_method == \"double\":\n",
    "        print(\"正在计算双侧区间\")\n",
    "        #! alpha = 1 - confidence_level，故而 1 + confidence_level) / 2 = 1- alpha / 2\n",
    "        t_value = t.ppf((1 + confidence_level) / 2, df=n - 1)\n",
    "    else:\n",
    "        print(\"正在计算单侧区间\")\n",
    "        t_value = t.ppf(confidence_level, df=n - 1)\n",
    "    margin_error = t_value * sample_std / np.sqrt(n)\n",
    "    lower_bound = center - margin_error\n",
    "    upper_bound = center + margin_error\n",
    "    if test_method == \"double\":\n",
    "        #! 决定是否接受假设的时候，可以直接用 sample_mean 和 bound 比较，也可以用 t_statistic 和统计量（比如 u_{1- alpha / 2}）作对比\n",
    "        print(f\"Confidence Interval[{confidence_level}]:\", lower_bound, \"-\", upper_bound)\n",
    "        if mu_0 != None:\n",
    "        #! p 和 confidence_level / alpha 没有任何关系，只有假设检验有 p 这个概念\n",
    "            p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df=n - 1))\n",
    "    elif test_method == \"right\":\n",
    "        #! 样本均值大于 right_bound 则拒绝假设\n",
    "        print(f\"Confidence Interval[{confidence_level}]:\", \"right_bound \", upper_bound)\n",
    "        if mu_0 != None:\n",
    "            p_value = 1 - t.cdf(t_statistic, df=n - 1)\n",
    "    elif test_method == \"left\":\n",
    "        #! 样本均值小于 left_bound 则拒绝假设\n",
    "        print(f\"Confidence Interval[{confidence_level}]:\", \"left_bound\", lower_bound)\n",
    "        if mu_0 != None:\n",
    "            p_value = t.cdf(t_statistic, df=n - 1)\n",
    "    if mu_0 != None:\n",
    "        print(f\"P-value: {p_value}\")\n",
    "        return p_value\n",
    "\n",
    "\n",
    "t_test(k_list, 0.95, mu_0=0.5, test_method=\"double\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常微分方程初值问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " solve_ivp(fun, t_span, y0, method='RK45', t_eval=None, dense_output=False,\n",
      "           events=None, vectorized=False, args=None, **options)\n",
      "\n",
      "Solve an initial value problem for a system of ODEs.\n",
      "\n",
      "This function numerically integrates a system of ordinary differential\n",
      "equations given an initial value::\n",
      "\n",
      "    dy / dt = f(t, y)\n",
      "    y(t0) = y0\n",
      "\n",
      "Here t is a 1-D independent variable (time), y(t) is an\n",
      "N-D vector-valued function (state), and an N-D\n",
      "vector-valued function f(t, y) determines the differential equations.\n",
      "The goal is to find y(t) approximately satisfying the differential\n",
      "equations, given an initial value y(t0)=y0.\n",
      "\n",
      "Some of the solvers support integration in the complex domain, but note\n",
      "that for stiff ODE solvers, the right-hand side must be\n",
      "complex-differentiable (satisfy Cauchy-Riemann equations [11]_).\n",
      "To solve a problem in the complex domain, pass y0 with a complex data type.\n",
      "Another option always available is to rewrite your problem for real and\n",
      "imaginary parts separately.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fun : callable\n",
      "    Right-hand side of the system. The calling signature is ``fun(t, y)``.\n",
      "    Here `t` is a scalar, and there are two options for the ndarray `y`:\n",
      "    It can either have shape (n,); then `fun` must return array_like with\n",
      "    shape (n,). Alternatively, it can have shape (n, k); then `fun`\n",
      "    must return an array_like with shape (n, k), i.e., each column\n",
      "    corresponds to a single column in `y`. The choice between the two\n",
      "    options is determined by `vectorized` argument (see below). The\n",
      "    vectorized implementation allows a faster approximation of the Jacobian\n",
      "    by finite differences (required for stiff solvers).\n",
      "t_span : 2-member sequence\n",
      "    Interval of integration (t0, tf). The solver starts with t=t0 and\n",
      "    integrates until it reaches t=tf. Both t0 and tf must be floats\n",
      "    or values interpretable by the float conversion function.\n",
      "y0 : array_like, shape (n,)\n",
      "    Initial state. For problems in the complex domain, pass `y0` with a\n",
      "    complex data type (even if the initial value is purely real).\n",
      "method : string or `OdeSolver`, optional\n",
      "    Integration method to use:\n",
      "\n",
      "        * 'RK45' (default): Explicit Runge-Kutta method of order 5(4) [1]_.\n",
      "          The error is controlled assuming accuracy of the fourth-order\n",
      "          method, but steps are taken using the fifth-order accurate\n",
      "          formula (local extrapolation is done). A quartic interpolation\n",
      "          polynomial is used for the dense output [2]_. Can be applied in\n",
      "          the complex domain.\n",
      "        * 'RK23': Explicit Runge-Kutta method of order 3(2) [3]_. The error\n",
      "          is controlled assuming accuracy of the second-order method, but\n",
      "          steps are taken using the third-order accurate formula (local\n",
      "          extrapolation is done). A cubic Hermite polynomial is used for the\n",
      "          dense output. Can be applied in the complex domain.\n",
      "        * 'DOP853': Explicit Runge-Kutta method of order 8 [13]_.\n",
      "          Python implementation of the \"DOP853\" algorithm originally\n",
      "          written in Fortran [14]_. A 7-th order interpolation polynomial\n",
      "          accurate to 7-th order is used for the dense output.\n",
      "          Can be applied in the complex domain.\n",
      "        * 'Radau': Implicit Runge-Kutta method of the Radau IIA family of\n",
      "          order 5 [4]_. The error is controlled with a third-order accurate\n",
      "          embedded formula. A cubic polynomial which satisfies the\n",
      "          collocation conditions is used for the dense output.\n",
      "        * 'BDF': Implicit multi-step variable-order (1 to 5) method based\n",
      "          on a backward differentiation formula for the derivative\n",
      "          approximation [5]_. The implementation follows the one described\n",
      "          in [6]_. A quasi-constant step scheme is used and accuracy is\n",
      "          enhanced using the NDF modification. Can be applied in the\n",
      "          complex domain.\n",
      "        * 'LSODA': Adams/BDF method with automatic stiffness detection and\n",
      "          switching [7]_, [8]_. This is a wrapper of the Fortran solver\n",
      "          from ODEPACK.\n",
      "\n",
      "    Explicit Runge-Kutta methods ('RK23', 'RK45', 'DOP853') should be used\n",
      "    for non-stiff problems and implicit methods ('Radau', 'BDF') for\n",
      "    stiff problems [9]_. Among Runge-Kutta methods, 'DOP853' is recommended\n",
      "    for solving with high precision (low values of `rtol` and `atol`).\n",
      "\n",
      "    If not sure, first try to run 'RK45'. If it makes unusually many\n",
      "    iterations, diverges, or fails, your problem is likely to be stiff and\n",
      "    you should use 'Radau' or 'BDF'. 'LSODA' can also be a good universal\n",
      "    choice, but it might be somewhat less convenient to work with as it\n",
      "    wraps old Fortran code.\n",
      "\n",
      "    You can also pass an arbitrary class derived from `OdeSolver` which\n",
      "    implements the solver.\n",
      "t_eval : array_like or None, optional\n",
      "    Times at which to store the computed solution, must be sorted and lie\n",
      "    within `t_span`. If None (default), use points selected by the solver.\n",
      "dense_output : bool, optional\n",
      "    Whether to compute a continuous solution. Default is False.\n",
      "events : callable, or list of callables, optional\n",
      "    Events to track. If None (default), no events will be tracked.\n",
      "    Each event occurs at the zeros of a continuous function of time and\n",
      "    state. Each function must have the signature ``event(t, y)`` and return\n",
      "    a float. The solver will find an accurate value of `t` at which\n",
      "    ``event(t, y(t)) = 0`` using a root-finding algorithm. By default, all\n",
      "    zeros will be found. The solver looks for a sign change over each step,\n",
      "    so if multiple zero crossings occur within one step, events may be\n",
      "    missed. Additionally each `event` function might have the following\n",
      "    attributes:\n",
      "\n",
      "        terminal: bool, optional\n",
      "            Whether to terminate integration if this event occurs.\n",
      "            Implicitly False if not assigned.\n",
      "        direction: float, optional\n",
      "            Direction of a zero crossing. If `direction` is positive,\n",
      "            `event` will only trigger when going from negative to positive,\n",
      "            and vice versa if `direction` is negative. If 0, then either\n",
      "            direction will trigger event. Implicitly 0 if not assigned.\n",
      "\n",
      "    You can assign attributes like ``event.terminal = True`` to any\n",
      "    function in Python.\n",
      "vectorized : bool, optional\n",
      "    Whether `fun` is implemented in a vectorized fashion. Default is False.\n",
      "args : tuple, optional\n",
      "    Additional arguments to pass to the user-defined functions.  If given,\n",
      "    the additional arguments are passed to all user-defined functions.\n",
      "    So if, for example, `fun` has the signature ``fun(t, y, a, b, c)``,\n",
      "    then `jac` (if given) and any event functions must have the same\n",
      "    signature, and `args` must be a tuple of length 3.\n",
      "**options\n",
      "    Options passed to a chosen solver. All options available for already\n",
      "    implemented solvers are listed below.\n",
      "first_step : float or None, optional\n",
      "    Initial step size. Default is `None` which means that the algorithm\n",
      "    should choose.\n",
      "max_step : float, optional\n",
      "    Maximum allowed step size. Default is np.inf, i.e., the step size is not\n",
      "    bounded and determined solely by the solver.\n",
      "rtol, atol : float or array_like, optional\n",
      "    Relative and absolute tolerances. The solver keeps the local error\n",
      "    estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a\n",
      "    relative accuracy (number of correct digits), while `atol` controls\n",
      "    absolute accuracy (number of correct decimal places). To achieve the\n",
      "    desired `rtol`, set `atol` to be smaller than the smallest value that\n",
      "    can be expected from ``rtol * abs(y)`` so that `rtol` dominates the\n",
      "    allowable error. If `atol` is larger than ``rtol * abs(y)`` the\n",
      "    number of correct digits is not guaranteed. Conversely, to achieve the\n",
      "    desired `atol` set `rtol` such that ``rtol * abs(y)`` is always smaller\n",
      "    than `atol`. If components of y have different scales, it might be\n",
      "    beneficial to set different `atol` values for different components by\n",
      "    passing array_like with shape (n,) for `atol`. Default values are\n",
      "    1e-3 for `rtol` and 1e-6 for `atol`.\n",
      "jac : array_like, sparse_matrix, callable or None, optional\n",
      "    Jacobian matrix of the right-hand side of the system with respect\n",
      "    to y, required by the 'Radau', 'BDF' and 'LSODA' method. The\n",
      "    Jacobian matrix has shape (n, n) and its element (i, j) is equal to\n",
      "    ``d f_i / d y_j``.  There are three ways to define the Jacobian:\n",
      "\n",
      "        * If array_like or sparse_matrix, the Jacobian is assumed to\n",
      "          be constant. Not supported by 'LSODA'.\n",
      "        * If callable, the Jacobian is assumed to depend on both\n",
      "          t and y; it will be called as ``jac(t, y)``, as necessary.\n",
      "          For 'Radau' and 'BDF' methods, the return value might be a\n",
      "          sparse matrix.\n",
      "        * If None (default), the Jacobian will be approximated by\n",
      "          finite differences.\n",
      "\n",
      "    It is generally recommended to provide the Jacobian rather than\n",
      "    relying on a finite-difference approximation.\n",
      "jac_sparsity : array_like, sparse matrix or None, optional\n",
      "    Defines a sparsity structure of the Jacobian matrix for a finite-\n",
      "    difference approximation. Its shape must be (n, n). This argument\n",
      "    is ignored if `jac` is not `None`. If the Jacobian has only few\n",
      "    non-zero elements in *each* row, providing the sparsity structure\n",
      "    will greatly speed up the computations [10]_. A zero entry means that\n",
      "    a corresponding element in the Jacobian is always zero. If None\n",
      "    (default), the Jacobian is assumed to be dense.\n",
      "    Not supported by 'LSODA', see `lband` and `uband` instead.\n",
      "lband, uband : int or None, optional\n",
      "    Parameters defining the bandwidth of the Jacobian for the 'LSODA'\n",
      "    method, i.e., ``jac[i, j] != 0 only for i - lband <= j <= i + uband``.\n",
      "    Default is None. Setting these requires your jac routine to return the\n",
      "    Jacobian in the packed format: the returned array must have ``n``\n",
      "    columns and ``uband + lband + 1`` rows in which Jacobian diagonals are\n",
      "    written. Specifically ``jac_packed[uband + i - j , j] = jac[i, j]``.\n",
      "    The same format is used in `scipy.linalg.solve_banded` (check for an\n",
      "    illustration).  These parameters can be also used with ``jac=None`` to\n",
      "    reduce the number of Jacobian elements estimated by finite differences.\n",
      "min_step : float, optional\n",
      "    The minimum allowed step size for 'LSODA' method.\n",
      "    By default `min_step` is zero.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Bunch object with the following fields defined:\n",
      "t : ndarray, shape (n_points,)\n",
      "    Time points.\n",
      "y : ndarray, shape (n, n_points)\n",
      "    Values of the solution at `t`.\n",
      "sol : `OdeSolution` or None\n",
      "    Found solution as `OdeSolution` instance; None if `dense_output` was\n",
      "    set to False.\n",
      "t_events : list of ndarray or None\n",
      "    Contains for each event type a list of arrays at which an event of\n",
      "    that type event was detected. None if `events` was None.\n",
      "y_events : list of ndarray or None\n",
      "    For each value of `t_events`, the corresponding value of the solution.\n",
      "    None if `events` was None.\n",
      "nfev : int\n",
      "    Number of evaluations of the right-hand side.\n",
      "njev : int\n",
      "    Number of evaluations of the Jacobian.\n",
      "nlu : int\n",
      "    Number of LU decompositions.\n",
      "status : int\n",
      "    Reason for algorithm termination:\n",
      "\n",
      "        * -1: Integration step failed.\n",
      "        *  0: The solver successfully reached the end of `tspan`.\n",
      "        *  1: A termination event occurred.\n",
      "\n",
      "message : string\n",
      "    Human-readable description of the termination reason.\n",
      "success : bool\n",
      "    True if the solver reached the interval end or a termination event\n",
      "    occurred (``status >= 0``).\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] J. R. Dormand, P. J. Prince, \"A family of embedded Runge-Kutta\n",
      "       formulae\", Journal of Computational and Applied Mathematics, Vol. 6,\n",
      "       No. 1, pp. 19-26, 1980.\n",
      ".. [2] L. W. Shampine, \"Some Practical Runge-Kutta Formulas\", Mathematics\n",
      "       of Computation,, Vol. 46, No. 173, pp. 135-150, 1986.\n",
      ".. [3] P. Bogacki, L.F. Shampine, \"A 3(2) Pair of Runge-Kutta Formulas\",\n",
      "       Appl. Math. Lett. Vol. 2, No. 4. pp. 321-325, 1989.\n",
      ".. [4] E. Hairer, G. Wanner, \"Solving Ordinary Differential Equations II:\n",
      "       Stiff and Differential-Algebraic Problems\", Sec. IV.8.\n",
      ".. [5] `Backward Differentiation Formula\n",
      "        <https://en.wikipedia.org/wiki/Backward_differentiation_formula>`_\n",
      "        on Wikipedia.\n",
      ".. [6] L. F. Shampine, M. W. Reichelt, \"THE MATLAB ODE SUITE\", SIAM J. SCI.\n",
      "       COMPUTE., Vol. 18, No. 1, pp. 1-22, January 1997.\n",
      ".. [7] A. C. Hindmarsh, \"ODEPACK, A Systematized Collection of ODE\n",
      "       Solvers,\" IMACS Transactions on Scientific Computation, Vol 1.,\n",
      "       pp. 55-64, 1983.\n",
      ".. [8] L. Petzold, \"Automatic selection of methods for solving stiff and\n",
      "       nonstiff systems of ordinary differential equations\", SIAM Journal\n",
      "       on Scientific and Statistical Computing, Vol. 4, No. 1, pp. 136-148,\n",
      "       1983.\n",
      ".. [9] `Stiff equation <https://en.wikipedia.org/wiki/Stiff_equation>`_ on\n",
      "       Wikipedia.\n",
      ".. [10] A. Curtis, M. J. D. Powell, and J. Reid, \"On the estimation of\n",
      "        sparse Jacobian matrices\", Journal of the Institute of Mathematics\n",
      "        and its Applications, 13, pp. 117-120, 1974.\n",
      ".. [11] `Cauchy-Riemann equations\n",
      "         <https://en.wikipedia.org/wiki/Cauchy-Riemann_equations>`_ on\n",
      "         Wikipedia.\n",
      ".. [12] `Lotka-Volterra equations\n",
      "        <https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations>`_\n",
      "        on Wikipedia.\n",
      ".. [13] E. Hairer, S. P. Norsett G. Wanner, \"Solving Ordinary Differential\n",
      "        Equations I: Nonstiff Problems\", Sec. II.\n",
      ".. [14] `Page with original Fortran code of DOP853\n",
      "        <http://www.unige.ch/~hairer/software.html>`_.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Basic exponential decay showing automatically chosen time points.\n",
      "\n",
      ">>> import numpy as np\n",
      ">>> from scipy.integrate import solve_ivp\n",
      ">>> def exponential_decay(t, y): return -0.5 * y\n",
      ">>> sol = solve_ivp(exponential_decay, [0, 10], [2, 4, 8])\n",
      ">>> print(sol.t)\n",
      "[ 0.          0.11487653  1.26364188  3.06061781  4.81611105  6.57445806\n",
      "  8.33328988 10.        ]\n",
      ">>> print(sol.y)\n",
      "[[2.         1.88836035 1.06327177 0.43319312 0.18017253 0.07483045\n",
      "  0.03107158 0.01350781]\n",
      " [4.         3.7767207  2.12654355 0.86638624 0.36034507 0.14966091\n",
      "  0.06214316 0.02701561]\n",
      " [8.         7.5534414  4.25308709 1.73277247 0.72069014 0.29932181\n",
      "  0.12428631 0.05403123]]\n",
      "\n",
      "Specifying points where the solution is desired.\n",
      "\n",
      ">>> sol = solve_ivp(exponential_decay, [0, 10], [2, 4, 8],\n",
      "...                 t_eval=[0, 1, 2, 4, 10])\n",
      ">>> print(sol.t)\n",
      "[ 0  1  2  4 10]\n",
      ">>> print(sol.y)\n",
      "[[2.         1.21305369 0.73534021 0.27066736 0.01350938]\n",
      " [4.         2.42610739 1.47068043 0.54133472 0.02701876]\n",
      " [8.         4.85221478 2.94136085 1.08266944 0.05403753]]\n",
      "\n",
      "Cannon fired upward with terminal event upon impact. The ``terminal`` and\n",
      "``direction`` fields of an event are applied by monkey patching a function.\n",
      "Here ``y[0]`` is position and ``y[1]`` is velocity. The projectile starts\n",
      "at position 0 with velocity +10. Note that the integration never reaches\n",
      "t=100 because the event is terminal.\n",
      "\n",
      ">>> def upward_cannon(t, y): return [y[1], -0.5]\n",
      ">>> def hit_ground(t, y): return y[0]\n",
      ">>> hit_ground.terminal = True\n",
      ">>> hit_ground.direction = -1\n",
      ">>> sol = solve_ivp(upward_cannon, [0, 100], [0, 10], events=hit_ground)\n",
      ">>> print(sol.t_events)\n",
      "[array([40.])]\n",
      ">>> print(sol.t)\n",
      "[0.00000000e+00 9.99900010e-05 1.09989001e-03 1.10988901e-02\n",
      " 1.11088891e-01 1.11098890e+00 1.11099890e+01 4.00000000e+01]\n",
      "\n",
      "Use `dense_output` and `events` to find position, which is 100, at the apex\n",
      "of the cannonball's trajectory. Apex is not defined as terminal, so both\n",
      "apex and hit_ground are found. There is no information at t=20, so the sol\n",
      "attribute is used to evaluate the solution. The sol attribute is returned\n",
      "by setting ``dense_output=True``. Alternatively, the `y_events` attribute\n",
      "can be used to access the solution at the time of the event.\n",
      "\n",
      ">>> def apex(t, y): return y[1]\n",
      ">>> sol = solve_ivp(upward_cannon, [0, 100], [0, 10],\n",
      "...                 events=(hit_ground, apex), dense_output=True)\n",
      ">>> print(sol.t_events)\n",
      "[array([40.]), array([20.])]\n",
      ">>> print(sol.t)\n",
      "[0.00000000e+00 9.99900010e-05 1.09989001e-03 1.10988901e-02\n",
      " 1.11088891e-01 1.11098890e+00 1.11099890e+01 4.00000000e+01]\n",
      ">>> print(sol.sol(sol.t_events[1][0]))\n",
      "[100.   0.]\n",
      ">>> print(sol.y_events)\n",
      "[array([[-5.68434189e-14, -1.00000000e+01]]), array([[1.00000000e+02, 1.77635684e-15]])]\n",
      "\n",
      "As an example of a system with additional parameters, we'll implement\n",
      "the Lotka-Volterra equations [12]_.\n",
      "\n",
      ">>> def lotkavolterra(t, z, a, b, c, d):\n",
      "...     x, y = z\n",
      "...     return [a*x - b*x*y, -c*y + d*x*y]\n",
      "...\n",
      "\n",
      "We pass in the parameter values a=1.5, b=1, c=3 and d=1 with the `args`\n",
      "argument.\n",
      "\n",
      ">>> sol = solve_ivp(lotkavolterra, [0, 15], [10, 5], args=(1.5, 1, 3, 1),\n",
      "...                 dense_output=True)\n",
      "\n",
      "Compute a dense solution and plot it.\n",
      "\n",
      ">>> t = np.linspace(0, 15, 300)\n",
      ">>> z = sol.sol(t)\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> plt.plot(t, z.T)\n",
      ">>> plt.xlabel('t')\n",
      ">>> plt.legend(['x', 'y'], shadow=True)\n",
      ">>> plt.title('Lotka-Volterra System')\n",
      ">>> plt.show()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144/382934652.py:3: DeprecationWarning: scipy.info is deprecated and will be removed in SciPy 2.0.0, use numpy.info instead\n",
      "  scipy.info(solve_ivp)\n"
     ]
    }
   ],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.info(scipy.integrate.solve_ivp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向前欧拉法+改进欧拉法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向前欧拉法得到的值为: 3.7812273803000007\n",
      "改进欧拉法得到的值为: 4.142242539824673\n",
      "向前欧拉法精度的误差： 0.373618105077135\n",
      "改进欧拉法精度的误差: 0.01260294555246233\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 微分方程右侧函数 f\n",
    "def f(t, y):\n",
    "    return y + 2 * t\n",
    "\n",
    "def forward_euler(h, t_end):\n",
    "    t = np.arange(0, t_end + h, h)\n",
    "    n = len(t)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = 1\n",
    "\n",
    "    for i in range(n-1):\n",
    "        y[i+1] = y[i] + h * f(t[i], y[i])\n",
    "\n",
    "    return t, y\n",
    "\n",
    "def improved_euler(h, t_end):\n",
    "    t = np.arange(0, t_end + h, h)\n",
    "    n = len(t)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = 1\n",
    "\n",
    "    for i in range(n-1):\n",
    "        y_expected = y[i] + h * f(t[i], y[i])\n",
    "        y[i+1] = y[i] + h / 2 * (f(t[i], y[i]) + f(t[i+1], y_expected))\n",
    "    return t, y\n",
    "\n",
    "# 精确解\n",
    "def exact_solution(t):\n",
    "    return 3 * np.exp(t) - 2 * t - 2\n",
    "\n",
    "h = 0.1\n",
    "t_end = 1\n",
    "\n",
    "# 向前欧拉法\n",
    "t_forward, y_forward = forward_euler(h, t_end)\n",
    "forward_euler_value = y_forward[-1]\n",
    "\n",
    "# 改进欧拉法\n",
    "t_improved, y_improved = improved_euler(h, t_end)\n",
    "improved_euler_value = y_improved[-1]\n",
    "\n",
    "# 精确解\n",
    "t_exact = np.linspace(0, t_end, 100)\n",
    "y_exact = exact_solution(t_exact)\n",
    "\n",
    "# 误差分析\n",
    "forward_euler_error = np.abs(forward_euler_value - exact_solution(t_end))\n",
    "improved_euler_error = np.abs(improved_euler_value - exact_solution(t_end))\n",
    "\n",
    "print(\"向前欧拉法得到的值为:\", forward_euler_value)\n",
    "print(\"改进欧拉法得到的值为:\", improved_euler_value)\n",
    "print(\"向前欧拉法精度的误差：\", forward_euler_error)\n",
    "print(\"改进欧拉法精度的误差:\", improved_euler_error)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进欧拉法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y161sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m t_end \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y161sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# 改进欧拉法\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y161sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m t_improved, y_improved \u001b[39m=\u001b[39m improved_euler(f, y0, t0, h, t_end)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y161sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mt_improved = \u001b[39m\u001b[39m{\u001b[39;00mt_improved\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y161sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_improved = \u001b[39m\u001b[39m{\u001b[39;00my_improved\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "def improved_euler(f, y0 = 1, t0 = 0, h = 0.1, t_end = 1):\n",
    "    t = np.arange(t0, t_end + 0.1 * h, h)\n",
    "    n = len(t)\n",
    "    y = np.zeros(n)\n",
    "    y[0] = y0\n",
    "\n",
    "    for i in range(n-1):\n",
    "        y_expected = y[i] + h * f(t[i], y[i])\n",
    "        y[i+1] = y[i] + h / 2 * (f(t[i], y[i]) + f(t[i+1], y_expected))\n",
    "        print(t[i+1], y[i+1])\n",
    "    return t, y\n",
    "\n",
    "y0 = 1.6\n",
    "t0 = 1\n",
    "h = 0.2\n",
    "t_end = 2\n",
    "\n",
    "# 改进欧拉法\n",
    "t_improved, y_improved = improved_euler(f, y0, t0, h, t_end)\n",
    "print(f\"t_improved = {t_improved}\")\n",
    "print(f\"y_improved = {y_improved}\")\n",
    "improved_euler_value = y_improved[-1]\n",
    "print(f\"improved_euler_value = {improved_euler_value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一阶常微分线性方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "sol = solve_ivp(\n",
    "        fun=lambda t, y: y ** 3 - np.exp(y) + t - 1,\n",
    "        y0=[1.6],\n",
    "        t_span=(1, 3),\n",
    "        t_eval=[2],\n",
    "        # dense_output=True\n",
    ")\n",
    "\n",
    "print(sol)\n",
    "print(sol.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二阶及以上的常微分线性方程/常微分线性方程组"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `solve_ivp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: Required step size is less than spacing between numbers.\n",
      "  success: False\n",
      "   status: -1\n",
      "        t: [ 5.236e-01]\n",
      "        y: [[ 1.732e+00]\n",
      "            [ 1.346e+00]]\n",
      "      sol: None\n",
      " t_events: None\n",
      " y_events: None\n",
      "     nfev: 101455\n",
      "     njev: 0\n",
      "      nlu: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144/141343170.py:27: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return - y2 / t + (1 / (4 * t ** 2) -1 ) * y1\n",
      "/tmp/ipykernel_1144/141343170.py:27: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return - y2 / t + (1 / (4 * t ** 2) -1 ) * y1\n",
      "/tmp/ipykernel_1144/141343170.py:27: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return - y2 / t + (1 / (4 * t ** 2) -1 ) * y1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "def ode_system(t, y):\n",
    "    \"\"\"\n",
    "    Defines the system of ODEs to be solved.\n",
    "    \n",
    "    Parameters:\n",
    "        t: float\n",
    "            The current time point.\n",
    "        y: array_like\n",
    "            An array with shape (2,) containing the values of y at the current time point.\n",
    "            \n",
    "    Returns:\n",
    "        dydt: array_like\n",
    "            An array with shape (2,) containing the derivatives of y at the current time point.\n",
    "    \"\"\"\n",
    "    y1, y2 = y[0], y[1]\n",
    "    dydt = [f1(y1, y2, t), f2(y1, y2, t)]\n",
    "    return dydt\n",
    "\n",
    "# Define the functions f1 and f2\n",
    "def f1(y1, y2, t):\n",
    "    return y2\n",
    "    \n",
    "def f2(y1, y2, t):\n",
    "    return - y2 / t + (1 / (4 * t ** 2) -1 ) * y1\n",
    "\n",
    "# Solve the system of ODEs\n",
    "t_span = (np.pi/2, 0)  # Time span to integrate over\n",
    "y0 = [2, -2/np.pi]  # Initial conditions for y1 and y2\n",
    "sol = solve_ivp(ode_system, t_span, y0, t_eval=[np.pi/6], first_step=0.0001, max_step=0.0001)\n",
    "\n",
    "print(sol)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `odeint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73205\n",
      "{'hu': array([-0.00591995, -0.01889346, -0.01889346, -0.01565965, -0.01565965,\n",
      "       -0.01565965, -0.01565965, -0.01565965, -0.01565965, -0.03131929,\n",
      "       -0.03131929, -0.03131929, -0.03131929, -0.03131929, -0.03131929,\n",
      "       -0.03131929, -0.03131929, -0.03131929, -0.03131929, -0.03131929,\n",
      "       -0.03131929, -0.03131929, -0.03131929, -0.03131929, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.04232654, -0.04232654, -0.04232654, -0.04232654, -0.04232654,\n",
      "       -0.03500456, -0.03500456, -0.03500456, -0.03500456, -0.03500456,\n",
      "       -0.03500456, -0.03500456, -0.03500456, -0.03500456, -0.03500456,\n",
      "       -0.03500456, -0.03500456, -0.03500456, -0.03500456, -0.03500456,\n",
      "       -0.03500456, -0.02901465, -0.02901465, -0.02901465, -0.02901465,\n",
      "       -0.02901465, -0.02901465, -0.02901465, -0.02901465, -0.02901465,\n",
      "       -0.02901465, -0.02901465, -0.02901465, -0.02901465, -0.02901465,\n",
      "       -0.02373555, -0.02373555, -0.02373555, -0.02373555, -0.02373555,\n",
      "       -0.02373555, -0.02373555, -0.02373555, -0.02373555]), 'tcur': array([1.55872664, 1.53391324, 1.53391324, 1.51825359, 1.50259395,\n",
      "       1.50259395, 1.4869343 , 1.47127465, 1.47127465, 1.43995536,\n",
      "       1.43995536, 1.43995536, 1.40863607, 1.40863607, 1.40863607,\n",
      "       1.37731677, 1.37731677, 1.37731677, 1.34599748, 1.34599748,\n",
      "       1.34599748, 1.31467819, 1.31467819, 1.31467819, 1.27235165,\n",
      "       1.27235165, 1.27235165, 1.27235165, 1.23002511, 1.23002511,\n",
      "       1.23002511, 1.23002511, 1.18769857, 1.18769857, 1.18769857,\n",
      "       1.18769857, 1.14537203, 1.14537203, 1.14537203, 1.14537203,\n",
      "       1.10304549, 1.10304549, 1.10304549, 1.10304549, 1.06071895,\n",
      "       1.06071895, 1.06071895, 1.06071895, 1.01839241, 1.01839241,\n",
      "       1.01839241, 1.01839241, 0.97606587, 0.97606587, 0.97606587,\n",
      "       0.97606587, 0.93373933, 0.93373933, 0.93373933, 0.93373933,\n",
      "       0.89873476, 0.89873476, 0.89873476, 0.8637302 , 0.8637302 ,\n",
      "       0.8637302 , 0.82872564, 0.82872564, 0.82872564, 0.82872564,\n",
      "       0.79372107, 0.79372107, 0.79372107, 0.75871651, 0.75871651,\n",
      "       0.75871651, 0.72970186, 0.72970186, 0.72970186, 0.70068721,\n",
      "       0.70068721, 0.70068721, 0.67167256, 0.67167256, 0.67167256,\n",
      "       0.64265792, 0.64265792, 0.61364327, 0.61364327, 0.61364327,\n",
      "       0.58990772, 0.58990772, 0.56617217, 0.56617217, 0.54243663,\n",
      "       0.54243663, 0.54243663, 0.51870108, 0.51870108]), 'tolsf': array([8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310, 8.29954994e-310,\n",
      "       8.29954994e-310, 8.29954994e-310, 8.29954994e-310]), 'tsw': array([1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633, 1.57079633,\n",
      "       1.57079633, 1.57079633, 1.57079633, 1.57079633]), 'nst': array([ 4,  6,  6,  7,  8,  8,  9, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13,\n",
      "       13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18,\n",
      "       18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22,\n",
      "       22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 26, 26, 26, 27, 27,\n",
      "       27, 27, 28, 28, 28, 29, 29, 29, 30, 30, 30, 31, 31, 31, 32, 32, 32,\n",
      "       33, 33, 34, 34, 34, 35, 35, 36, 36, 37, 37, 37, 38, 38],\n",
      "      dtype=int32), 'nfe': array([ 9, 15, 15, 19, 21, 21, 23, 25, 25, 27, 27, 27, 29, 29, 29, 31, 31,\n",
      "       31, 33, 33, 33, 35, 35, 35, 37, 37, 37, 37, 39, 39, 39, 39, 41, 41,\n",
      "       41, 41, 43, 43, 43, 43, 45, 45, 45, 45, 47, 47, 47, 47, 49, 49, 49,\n",
      "       49, 51, 51, 51, 51, 53, 53, 53, 53, 57, 57, 57, 59, 59, 59, 61, 61,\n",
      "       61, 61, 63, 63, 63, 65, 65, 65, 69, 69, 69, 71, 71, 71, 73, 73, 73,\n",
      "       75, 75, 77, 77, 77, 81, 81, 83, 83, 85, 85, 85, 87, 87],\n",
      "      dtype=int32), 'nje': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'nqu': array([2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32), 'imxer': -1, 'lenrw': 52, 'leniw': 22, 'mused': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), 'message': 'Integration successful.'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "def f(y, x):\n",
    "    \"\"\"\n",
    "    定义二阶微分方程\n",
    "\n",
    "    :param y: 因变量\n",
    "    :param x: 自变量\n",
    "    :return: 二阶微分方程的值\n",
    "    \"\"\"\n",
    "    return [y[1], -(x * y[1] + (x ** 2 - 1/4) * y[0]) / (x ** 2)]\n",
    "\n",
    "# 初始条件\n",
    "y_a = [2, -2/np.pi]\n",
    "\n",
    "# 自变量范围\n",
    "x = np.linspace(np.pi/2, np.pi/6, 100)\n",
    "\n",
    "# 求解微分方程\n",
    "y, info = odeint(f, y_a, x, \n",
    "                #  full_output=True\n",
    "                )\n",
    "\n",
    "# 输出结果\n",
    "print(round(y[-1, 0], 5))\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16353624 0.48874799]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "def f(y, x):\n",
    "    \"\"\"\n",
    "    定义二阶微分方程\n",
    "\n",
    "    :param y: 因变量\n",
    "    :param x: 自变量\n",
    "    :return: 二阶微分方程的值\n",
    "    \"\"\"\n",
    "    return [y[1], y[0] * np.sin(x)]\n",
    "\n",
    "# 初始条件\n",
    "y_a = [1, 0]\n",
    "\n",
    "# 自变量范围\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# 求解微分方程\n",
    "# y, info = odeint(f, y_a, x, full_output=True)\n",
    "# print(info)\n",
    "\n",
    "\n",
    "y = odeint(f, y_a, x, full_output=False)\n",
    "\n",
    "# 输出结果\n",
    "print(y[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迭代法解非线性方程"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一般的迭代法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: 1.4483860173257999\n",
      "Iterations: 10\n",
      "Convergence order: 29.129846147766315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4483860173257999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def iteration_solve(x0, max_iter = 1000):\n",
    "    tolerance = 1e-5  # 容许误差\n",
    "\n",
    "    x_prev = x0\n",
    "    x_next = math.acos(0.25 * x_prev + math.cos(3) + 0.75)\n",
    "    iteration = 1\n",
    "\n",
    "    while abs(x_next - x_prev) > tolerance and iteration < max_iter:\n",
    "        x_prev = x_next\n",
    "        x_next = math.acos(0.25 * x_prev + math.cos(3) + 0.75)\n",
    "        iteration += 1\n",
    "\n",
    "    root = x_next\n",
    "    convergence_order = math.log(abs(root - x_prev)) / math.log(abs(x_prev - x0))\n",
    "\n",
    "    print('Root:', root)\n",
    "    print('Iterations:', iteration)\n",
    "    print('Convergence order:', convergence_order)\n",
    "    \n",
    "    return root\n",
    "\n",
    "x0 = 0.8\n",
    "\n",
    "iteration_solve(x0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as spi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return np.cos(np.exp(3 / (x + 1))) * np.sin(2 * x)\n",
    "\n",
    "def calculate_z(x):\n",
    "    z = []\n",
    "    for k in range(len(x)):\n",
    "        integral, _ = spi.quad(f, 0, x[k])\n",
    "        z.append(integral)\n",
    "    return z\n",
    "\n",
    "def plot_graph(x, z):\n",
    "    plt.plot(x, z)\n",
    "    plt.plot(x, [0.36] * len(x), 'r')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_xx():\n",
    "    xx = [2]\n",
    "    for k in range(8):\n",
    "        ff, _ = spi.quad(f, 0, xx[k])\n",
    "        ff -= 0.36\n",
    "        fd = np.cos(np.exp(3 / (xx[k] + 1))) * np.sin(2 * xx[k])\n",
    "        xx.append(xx[k] - ff / fd)\n",
    "    return xx[8]\n",
    "\n",
    "x = np.arange(0, 10.1, 0.1)\n",
    "z = calculate_z(x)\n",
    "plot_graph(x, z)\n",
    "result = calculate_xx()\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本矩阵运算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU 分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: [[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "L: [[ 1.          0.          0.        ]\n",
      " [-0.6         1.          0.        ]\n",
      " [-0.2         0.52941176  1.        ]]\n",
      "U: [[ 5.         -1.         -3.        ]\n",
      " [ 0.          3.4        13.2       ]\n",
      " [ 0.          0.         -3.58823529]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[5, -1, -3], \n",
    "              [-1, 2, 4],\n",
    "              [-3, 4, 15]])\n",
    "\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print(\"P:\", P)\n",
    "print(\"L:\", L)\n",
    "print(\"U:\", U)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky 分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U =\n",
      "[[ 2.23606798  0.          0.        ]\n",
      " [-0.4472136   1.34164079  0.        ]\n",
      " [-1.34164079  2.53421037  2.60341656]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[5, -1, -3], [-1, 2, 4], [-3, 4, 15]])\n",
    "\n",
    "U = np.linalg.cholesky(A)\n",
    "\n",
    "x = np.linalg.solve(U.T, np.linalg.solve(U, b))\n",
    "\n",
    "print(\"U =\")\n",
    "print(U)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性方程组/矩阵方程求解"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵方程求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用列主元Gauss消去法求解得到 x = [1.  0.5 0.5]\n",
      "条件数Cond2(A) = 34.55112166226198\n",
      "使用Gauss-Seidel迭代法求解5次得到 x(5) = [0 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[4, 2, -2], [1, 1, 1], [2, 2, 4]])\n",
    "b = np.array([4, 2, 5])\n",
    "x0 = np.array([1, 1, 1])\n",
    "\n",
    "# 使用列主元Gauss消去法求解\n",
    "x_gauss = np.linalg.solve(A, b)\n",
    "cond_A = np.linalg.cond(A, 2)\n",
    "\n",
    "print(\"使用列主元Gauss消去法求解得到 x =\", x_gauss)\n",
    "print(\"条件数Cond2(A) =\", cond_A)\n",
    "print(\"使用Gauss-Seidel迭代法求解5次得到 x(5) =\", x_gs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.   0.   2.   4.   0. ]\n",
      " [ 0.7 -1.   0.   0.   0. ]\n",
      " [ 0.   0.7 -1.   0.   0. ]\n",
      " [ 0.   0.   0.8 -1.   0. ]\n",
      " [ 0.   0.   0.   0.8 -1. ]]\n",
      "[2000. 1000.  500.  250.  100.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "\n",
    "n = 5\n",
    "b = [0,0,2,4,0]\n",
    "d = np.array([0.3,0.3,0.2,0.2])\n",
    "s = 1 - d\n",
    "h = [0, 400, 200, 150, 100]\n",
    "\n",
    "L = diags([s], [-1]).toarray()\n",
    "L[0,:] += b\n",
    "neg_unit = diags([[-1 for _ in range(n)]], [0]).toarray()\n",
    "A = L + neg_unit\n",
    "\n",
    "print(A)\n",
    "\n",
    "# A = diags(np.ones(n)).toarray()\n",
    "\n",
    "x = np.linalg.solve(A, h)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        +0.j        ,  1.29818991+0.j        ,\n",
       "       -0.19529393+1.13695161j, -0.19529393-1.13695161j,\n",
       "       -0.90760204+0.j        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(L)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.867813041786082\n",
      "0.005\n",
      "0.07433906520893041\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "order = 1\n",
    "\n",
    "A=np.array([\n",
    "    [5, -7, 0, 1],\n",
    "    [-3,22,6,2],\n",
    "    [5,-1,31,-1],\n",
    "    [2,1,0,23]\n",
    "])\n",
    "b = np.array([6,3,4,7])\n",
    "pert_b = np.array([0,0,0,0.1])\n",
    "\n",
    "cond_A = np.linalg.cond(A, p=order)\n",
    "print(cond_A)\n",
    "\n",
    "rel_pert_b = np.linalg.norm(pert_b, ord=order) / np.linalg.norm(b, ord=order)\n",
    "print(rel_pert_b)\n",
    "\n",
    "sup_rel_err_x = cond_A * rel_pert_b\n",
    "print(sup_rel_err_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_A = 1053.4789912002955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "order = 2\n",
    "n = 50\n",
    "diag = np.ones(50) * 2\n",
    "subdiag = np.ones(49)\n",
    "A = diags([subdiag, diag, subdiag] , [-1, 0, 1]).toarray()\n",
    "# print(f\"A = {A}\")\n",
    "cond_2_A = np.linalg.cond(A, p=order)\n",
    "print(f\"cond_2_A = {cond_2_A}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯-赛德尔迭代法（Gauss-Sedeil）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x^(5) = [ 1.71597235  0.39264682 -0.1305711   0.13806124]\n",
      "relative error = 0.01541933644526515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.71597235,  0.39264682, -0.1305711 ,  0.13806124]),\n",
       " 0.01541933644526515)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gauss_sedeil(A, b, x0, tol, max_iter, verbose = True):\n",
    "    x = x0.copy()\n",
    "\n",
    "    # 求 D_sub_L_inv\n",
    "    D = np.diag(np.diag(A))\n",
    "    U = -(np.triu(A) - D)\n",
    "    L = -(np.tril(A) - D)\n",
    "    D_sub_L_inv = np.linalg.inv(D - L)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # print(f\"x^({i}) = {x}\")\n",
    "\n",
    "        x_new = D_sub_L_inv @ (U @ x + b)\n",
    "        err = np.linalg.norm(x_new - x)\n",
    "        \n",
    "        x = x_new\n",
    "        if  err < tol:\n",
    "            if verbose: print(f\"Converge after {i+1} iterations\")\n",
    "            break\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"x^({i+1}) = {x}\")\n",
    "        print(f\"relative error = {err}\")\n",
    "    return x, err\n",
    "\n",
    "gauss_sedeil(A=A,b=b,x0=np.zeros(4),tol=1e-6,max_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge after 16 iterations\n",
      "x^(16) = [ 1.72603719  0.3953224  -0.1321869   0.1370697 ]\n",
      "relative error = 6.135494817040176e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.72603719,  0.3953224 , -0.1321869 ,  0.1370697 ]),\n",
       " 6.135494817040176e-07)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_sedeil(A=A,b=b,x0=np.zeros(4),tol=1e-6,max_iter=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "谱半径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_B_G_S(A):\n",
    "    \"\"\"求 G-S 迭代的迭代矩阵\"\"\" \n",
    "    D = np.diag(np.diag(A))\n",
    "    U = -(np.triu(A) - D)\n",
    "    L = -(np.tril(A) - D)\n",
    "    D_sub_L_inv = np.linalg.inv(D - L)\n",
    "    B_G_S = D_sub_L_inv @ U \n",
    "    \n",
    "    return B_G_S\n",
    "\n",
    "B_G_S = cal_B_G_S(A)\n",
    "# print(B_G_S)\n",
    "# 求 B_G_S 的谱半径\n",
    "rho_B_G_S = np.max(np.abs(np.linalg.eigvals(B_G_S)))\n",
    "print(rho_B_G_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_B_G_S = 0.9962102548359681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "\n",
    "def cal_B_G_S(A):\n",
    "    \"\"\"求 G-S 迭代的迭代矩阵\"\"\" \n",
    "    D = np.diag(np.diag(A))\n",
    "    U = -(np.triu(A) - D)\n",
    "    L = -(np.tril(A) - D)\n",
    "    D_sub_L_inv = np.linalg.inv(D - L)\n",
    "    B_G_S = D_sub_L_inv @ U \n",
    "    \n",
    "    return B_G_S\n",
    "\n",
    "order = 2\n",
    "n = 50\n",
    "diag = np.ones(50) * 2\n",
    "subdiag = np.ones(49)\n",
    "A = diags([subdiag, diag, subdiag] , [-1, 0, 1]).toarray()\n",
    "\n",
    "\n",
    "B_G_S = cal_B_G_S(A)\n",
    "# print(B_G_S)\n",
    "# 求 B_G_S 的谱半径\n",
    "rho_B_G_S = np.max(np.abs(np.linalg.eigvals(B_G_S)))\n",
    "print(f\"rho_B_G_S = {rho_B_G_S}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " least_squares(fun, x0, jac='2-point', bounds=(-inf, inf), method='trf',\n",
      "               ftol=1e-08, xtol=1e-08, gtol=1e-08, x_scale=1.0, loss='linear',\n",
      "               f_scale=1.0, diff_step=None, tr_solver=None, tr_options={},\n",
      "               jac_sparsity=None, max_nfev=None, verbose=0, args=(),\n",
      "               kwargs={})\n",
      "\n",
      "Solve a nonlinear least-squares problem with bounds on the variables.\n",
      "\n",
      "Given the residuals f(x) (an m-D real function of n real\n",
      "variables) and the loss function rho(s) (a scalar function), `least_squares`\n",
      "finds a local minimum of the cost function F(x)::\n",
      "\n",
      "    minimize F(x) = 0.5 * sum(rho(f_i(x)**2), i = 0, ..., m - 1)\n",
      "    subject to lb <= x <= ub\n",
      "\n",
      "The purpose of the loss function rho(s) is to reduce the influence of\n",
      "outliers on the solution.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fun : callable\n",
      "    Function which computes the vector of residuals, with the signature\n",
      "    ``fun(x, *args, **kwargs)``, i.e., the minimization proceeds with\n",
      "    respect to its first argument. The argument ``x`` passed to this\n",
      "    function is an ndarray of shape (n,) (never a scalar, even for n=1).\n",
      "    It must allocate and return a 1-D array_like of shape (m,) or a scalar.\n",
      "    If the argument ``x`` is complex or the function ``fun`` returns\n",
      "    complex residuals, it must be wrapped in a real function of real\n",
      "    arguments, as shown at the end of the Examples section.\n",
      "x0 : array_like with shape (n,) or float\n",
      "    Initial guess on independent variables. If float, it will be treated\n",
      "    as a 1-D array with one element.\n",
      "jac : {'2-point', '3-point', 'cs', callable}, optional\n",
      "    Method of computing the Jacobian matrix (an m-by-n matrix, where\n",
      "    element (i, j) is the partial derivative of f[i] with respect to\n",
      "    x[j]). The keywords select a finite difference scheme for numerical\n",
      "    estimation. The scheme '3-point' is more accurate, but requires\n",
      "    twice as many operations as '2-point' (default). The scheme 'cs'\n",
      "    uses complex steps, and while potentially the most accurate, it is\n",
      "    applicable only when `fun` correctly handles complex inputs and\n",
      "    can be analytically continued to the complex plane. Method 'lm'\n",
      "    always uses the '2-point' scheme. If callable, it is used as\n",
      "    ``jac(x, *args, **kwargs)`` and should return a good approximation\n",
      "    (or the exact value) for the Jacobian as an array_like (np.atleast_2d\n",
      "    is applied), a sparse matrix (csr_matrix preferred for performance) or\n",
      "    a `scipy.sparse.linalg.LinearOperator`.\n",
      "bounds : 2-tuple of array_like or `Bounds`, optional\n",
      "    There are two ways to specify bounds:\n",
      "\n",
      "        1. Instance of `Bounds` class\n",
      "        2. Lower and upper bounds on independent variables. Defaults to no\n",
      "           bounds. Each array must match the size of `x0` or be a scalar,\n",
      "           in the latter case a bound will be the same for all variables.\n",
      "           Use ``np.inf`` with an appropriate sign to disable bounds on all\n",
      "           or some variables.\n",
      "method : {'trf', 'dogbox', 'lm'}, optional\n",
      "    Algorithm to perform minimization.\n",
      "\n",
      "        * 'trf' : Trust Region Reflective algorithm, particularly suitable\n",
      "          for large sparse problems with bounds. Generally robust method.\n",
      "        * 'dogbox' : dogleg algorithm with rectangular trust regions,\n",
      "          typical use case is small problems with bounds. Not recommended\n",
      "          for problems with rank-deficient Jacobian.\n",
      "        * 'lm' : Levenberg-Marquardt algorithm as implemented in MINPACK.\n",
      "          Doesn't handle bounds and sparse Jacobians. Usually the most\n",
      "          efficient method for small unconstrained problems.\n",
      "\n",
      "    Default is 'trf'. See Notes for more information.\n",
      "ftol : float or None, optional\n",
      "    Tolerance for termination by the change of the cost function. Default\n",
      "    is 1e-8. The optimization process is stopped when ``dF < ftol * F``,\n",
      "    and there was an adequate agreement between a local quadratic model and\n",
      "    the true model in the last step.\n",
      "\n",
      "    If None and 'method' is not 'lm', the termination by this condition is\n",
      "    disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "    machine epsilon.\n",
      "xtol : float or None, optional\n",
      "    Tolerance for termination by the change of the independent variables.\n",
      "    Default is 1e-8. The exact condition depends on the `method` used:\n",
      "\n",
      "        * For 'trf' and 'dogbox' : ``norm(dx) < xtol * (xtol + norm(x))``.\n",
      "        * For 'lm' : ``Delta < xtol * norm(xs)``, where ``Delta`` is\n",
      "          a trust-region radius and ``xs`` is the value of ``x``\n",
      "          scaled according to `x_scale` parameter (see below).\n",
      "\n",
      "    If None and 'method' is not 'lm', the termination by this condition is\n",
      "    disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "    machine epsilon.\n",
      "gtol : float or None, optional\n",
      "    Tolerance for termination by the norm of the gradient. Default is 1e-8.\n",
      "    The exact condition depends on a `method` used:\n",
      "\n",
      "        * For 'trf' : ``norm(g_scaled, ord=np.inf) < gtol``, where\n",
      "          ``g_scaled`` is the value of the gradient scaled to account for\n",
      "          the presence of the bounds [STIR]_.\n",
      "        * For 'dogbox' : ``norm(g_free, ord=np.inf) < gtol``, where\n",
      "          ``g_free`` is the gradient with respect to the variables which\n",
      "          are not in the optimal state on the boundary.\n",
      "        * For 'lm' : the maximum absolute value of the cosine of angles\n",
      "          between columns of the Jacobian and the residual vector is less\n",
      "          than `gtol`, or the residual vector is zero.\n",
      "\n",
      "    If None and 'method' is not 'lm', the termination by this condition is\n",
      "    disabled. If 'method' is 'lm', this tolerance must be higher than\n",
      "    machine epsilon.\n",
      "x_scale : array_like or 'jac', optional\n",
      "    Characteristic scale of each variable. Setting `x_scale` is equivalent\n",
      "    to reformulating the problem in scaled variables ``xs = x / x_scale``.\n",
      "    An alternative view is that the size of a trust region along jth\n",
      "    dimension is proportional to ``x_scale[j]``. Improved convergence may\n",
      "    be achieved by setting `x_scale` such that a step of a given size\n",
      "    along any of the scaled variables has a similar effect on the cost\n",
      "    function. If set to 'jac', the scale is iteratively updated using the\n",
      "    inverse norms of the columns of the Jacobian matrix (as described in\n",
      "    [JJMore]_).\n",
      "loss : str or callable, optional\n",
      "    Determines the loss function. The following keyword values are allowed:\n",
      "\n",
      "        * 'linear' (default) : ``rho(z) = z``. Gives a standard\n",
      "          least-squares problem.\n",
      "        * 'soft_l1' : ``rho(z) = 2 * ((1 + z)**0.5 - 1)``. The smooth\n",
      "          approximation of l1 (absolute value) loss. Usually a good\n",
      "          choice for robust least squares.\n",
      "        * 'huber' : ``rho(z) = z if z <= 1 else 2*z**0.5 - 1``. Works\n",
      "          similarly to 'soft_l1'.\n",
      "        * 'cauchy' : ``rho(z) = ln(1 + z)``. Severely weakens outliers\n",
      "          influence, but may cause difficulties in optimization process.\n",
      "        * 'arctan' : ``rho(z) = arctan(z)``. Limits a maximum loss on\n",
      "          a single residual, has properties similar to 'cauchy'.\n",
      "\n",
      "    If callable, it must take a 1-D ndarray ``z=f**2`` and return an\n",
      "    array_like with shape (3, m) where row 0 contains function values,\n",
      "    row 1 contains first derivatives and row 2 contains second\n",
      "    derivatives. Method 'lm' supports only 'linear' loss.\n",
      "f_scale : float, optional\n",
      "    Value of soft margin between inlier and outlier residuals, default\n",
      "    is 1.0. The loss function is evaluated as follows\n",
      "    ``rho_(f**2) = C**2 * rho(f**2 / C**2)``, where ``C`` is `f_scale`,\n",
      "    and ``rho`` is determined by `loss` parameter. This parameter has\n",
      "    no effect with ``loss='linear'``, but for other `loss` values it is\n",
      "    of crucial importance.\n",
      "max_nfev : None or int, optional\n",
      "    Maximum number of function evaluations before the termination.\n",
      "    If None (default), the value is chosen automatically:\n",
      "\n",
      "        * For 'trf' and 'dogbox' : 100 * n.\n",
      "        * For 'lm' :  100 * n if `jac` is callable and 100 * n * (n + 1)\n",
      "          otherwise (because 'lm' counts function calls in Jacobian\n",
      "          estimation).\n",
      "\n",
      "diff_step : None or array_like, optional\n",
      "    Determines the relative step size for the finite difference\n",
      "    approximation of the Jacobian. The actual step is computed as\n",
      "    ``x * diff_step``. If None (default), then `diff_step` is taken to be\n",
      "    a conventional \"optimal\" power of machine epsilon for the finite\n",
      "    difference scheme used [NR]_.\n",
      "tr_solver : {None, 'exact', 'lsmr'}, optional\n",
      "    Method for solving trust-region subproblems, relevant only for 'trf'\n",
      "    and 'dogbox' methods.\n",
      "\n",
      "        * 'exact' is suitable for not very large problems with dense\n",
      "          Jacobian matrices. The computational complexity per iteration is\n",
      "          comparable to a singular value decomposition of the Jacobian\n",
      "          matrix.\n",
      "        * 'lsmr' is suitable for problems with sparse and large Jacobian\n",
      "          matrices. It uses the iterative procedure\n",
      "          `scipy.sparse.linalg.lsmr` for finding a solution of a linear\n",
      "          least-squares problem and only requires matrix-vector product\n",
      "          evaluations.\n",
      "\n",
      "    If None (default), the solver is chosen based on the type of Jacobian\n",
      "    returned on the first iteration.\n",
      "tr_options : dict, optional\n",
      "    Keyword options passed to trust-region solver.\n",
      "\n",
      "        * ``tr_solver='exact'``: `tr_options` are ignored.\n",
      "        * ``tr_solver='lsmr'``: options for `scipy.sparse.linalg.lsmr`.\n",
      "          Additionally,  ``method='trf'`` supports  'regularize' option\n",
      "          (bool, default is True), which adds a regularization term to the\n",
      "          normal equation, which improves convergence if the Jacobian is\n",
      "          rank-deficient [Byrd]_ (eq. 3.4).\n",
      "\n",
      "jac_sparsity : {None, array_like, sparse matrix}, optional\n",
      "    Defines the sparsity structure of the Jacobian matrix for finite\n",
      "    difference estimation, its shape must be (m, n). If the Jacobian has\n",
      "    only few non-zero elements in *each* row, providing the sparsity\n",
      "    structure will greatly speed up the computations [Curtis]_. A zero\n",
      "    entry means that a corresponding element in the Jacobian is identically\n",
      "    zero. If provided, forces the use of 'lsmr' trust-region solver.\n",
      "    If None (default), then dense differencing will be used. Has no effect\n",
      "    for 'lm' method.\n",
      "verbose : {0, 1, 2}, optional\n",
      "    Level of algorithm's verbosity:\n",
      "\n",
      "        * 0 (default) : work silently.\n",
      "        * 1 : display a termination report.\n",
      "        * 2 : display progress during iterations (not supported by 'lm'\n",
      "          method).\n",
      "\n",
      "args, kwargs : tuple and dict, optional\n",
      "    Additional arguments passed to `fun` and `jac`. Both empty by default.\n",
      "    The calling signature is ``fun(x, *args, **kwargs)`` and the same for\n",
      "    `jac`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : OptimizeResult\n",
      "    `OptimizeResult` with the following fields defined:\n",
      "\n",
      "        x : ndarray, shape (n,)\n",
      "            Solution found.\n",
      "        cost : float\n",
      "            Value of the cost function at the solution.\n",
      "        fun : ndarray, shape (m,)\n",
      "            Vector of residuals at the solution.\n",
      "        jac : ndarray, sparse matrix or LinearOperator, shape (m, n)\n",
      "            Modified Jacobian matrix at the solution, in the sense that J^T J\n",
      "            is a Gauss-Newton approximation of the Hessian of the cost function.\n",
      "            The type is the same as the one used by the algorithm.\n",
      "        grad : ndarray, shape (m,)\n",
      "            Gradient of the cost function at the solution.\n",
      "        optimality : float\n",
      "            First-order optimality measure. In unconstrained problems, it is\n",
      "            always the uniform norm of the gradient. In constrained problems,\n",
      "            it is the quantity which was compared with `gtol` during iterations.\n",
      "        active_mask : ndarray of int, shape (n,)\n",
      "            Each component shows whether a corresponding constraint is active\n",
      "            (that is, whether a variable is at the bound):\n",
      "\n",
      "                *  0 : a constraint is not active.\n",
      "                * -1 : a lower bound is active.\n",
      "                *  1 : an upper bound is active.\n",
      "\n",
      "            Might be somewhat arbitrary for 'trf' method as it generates a\n",
      "            sequence of strictly feasible iterates and `active_mask` is\n",
      "            determined within a tolerance threshold.\n",
      "        nfev : int\n",
      "            Number of function evaluations done. Methods 'trf' and 'dogbox' do\n",
      "            not count function calls for numerical Jacobian approximation, as\n",
      "            opposed to 'lm' method.\n",
      "        njev : int or None\n",
      "            Number of Jacobian evaluations done. If numerical Jacobian\n",
      "            approximation is used in 'lm' method, it is set to None.\n",
      "        status : int\n",
      "            The reason for algorithm termination:\n",
      "\n",
      "                * -1 : improper input parameters status returned from MINPACK.\n",
      "                *  0 : the maximum number of function evaluations is exceeded.\n",
      "                *  1 : `gtol` termination condition is satisfied.\n",
      "                *  2 : `ftol` termination condition is satisfied.\n",
      "                *  3 : `xtol` termination condition is satisfied.\n",
      "                *  4 : Both `ftol` and `xtol` termination conditions are satisfied.\n",
      "\n",
      "        message : str\n",
      "            Verbal description of the termination reason.\n",
      "        success : bool\n",
      "            True if one of the convergence criteria is satisfied (`status` > 0).\n",
      "\n",
      "See Also\n",
      "--------\n",
      "leastsq : A legacy wrapper for the MINPACK implementation of the\n",
      "          Levenberg-Marquadt algorithm.\n",
      "curve_fit : Least-squares minimization applied to a curve-fitting problem.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Method 'lm' (Levenberg-Marquardt) calls a wrapper over least-squares\n",
      "algorithms implemented in MINPACK (lmder, lmdif). It runs the\n",
      "Levenberg-Marquardt algorithm formulated as a trust-region type algorithm.\n",
      "The implementation is based on paper [JJMore]_, it is very robust and\n",
      "efficient with a lot of smart tricks. It should be your first choice\n",
      "for unconstrained problems. Note that it doesn't support bounds. Also,\n",
      "it doesn't work when m < n.\n",
      "\n",
      "Method 'trf' (Trust Region Reflective) is motivated by the process of\n",
      "solving a system of equations, which constitute the first-order optimality\n",
      "condition for a bound-constrained minimization problem as formulated in\n",
      "[STIR]_. The algorithm iteratively solves trust-region subproblems\n",
      "augmented by a special diagonal quadratic term and with trust-region shape\n",
      "determined by the distance from the bounds and the direction of the\n",
      "gradient. This enhancements help to avoid making steps directly into bounds\n",
      "and efficiently explore the whole space of variables. To further improve\n",
      "convergence, the algorithm considers search directions reflected from the\n",
      "bounds. To obey theoretical requirements, the algorithm keeps iterates\n",
      "strictly feasible. With dense Jacobians trust-region subproblems are\n",
      "solved by an exact method very similar to the one described in [JJMore]_\n",
      "(and implemented in MINPACK). The difference from the MINPACK\n",
      "implementation is that a singular value decomposition of a Jacobian\n",
      "matrix is done once per iteration, instead of a QR decomposition and series\n",
      "of Givens rotation eliminations. For large sparse Jacobians a 2-D subspace\n",
      "approach of solving trust-region subproblems is used [STIR]_, [Byrd]_.\n",
      "The subspace is spanned by a scaled gradient and an approximate\n",
      "Gauss-Newton solution delivered by `scipy.sparse.linalg.lsmr`. When no\n",
      "constraints are imposed the algorithm is very similar to MINPACK and has\n",
      "generally comparable performance. The algorithm works quite robust in\n",
      "unbounded and bounded problems, thus it is chosen as a default algorithm.\n",
      "\n",
      "Method 'dogbox' operates in a trust-region framework, but considers\n",
      "rectangular trust regions as opposed to conventional ellipsoids [Voglis]_.\n",
      "The intersection of a current trust region and initial bounds is again\n",
      "rectangular, so on each iteration a quadratic minimization problem subject\n",
      "to bound constraints is solved approximately by Powell's dogleg method\n",
      "[NumOpt]_. The required Gauss-Newton step can be computed exactly for\n",
      "dense Jacobians or approximately by `scipy.sparse.linalg.lsmr` for large\n",
      "sparse Jacobians. The algorithm is likely to exhibit slow convergence when\n",
      "the rank of Jacobian is less than the number of variables. The algorithm\n",
      "often outperforms 'trf' in bounded problems with a small number of\n",
      "variables.\n",
      "\n",
      "Robust loss functions are implemented as described in [BA]_. The idea\n",
      "is to modify a residual vector and a Jacobian matrix on each iteration\n",
      "such that computed gradient and Gauss-Newton Hessian approximation match\n",
      "the true gradient and Hessian approximation of the cost function. Then\n",
      "the algorithm proceeds in a normal way, i.e., robust loss functions are\n",
      "implemented as a simple wrapper over standard least-squares algorithms.\n",
      "\n",
      ".. versionadded:: 0.17.0\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [STIR] M. A. Branch, T. F. Coleman, and Y. Li, \"A Subspace, Interior,\n",
      "          and Conjugate Gradient Method for Large-Scale Bound-Constrained\n",
      "          Minimization Problems,\" SIAM Journal on Scientific Computing,\n",
      "          Vol. 21, Number 1, pp 1-23, 1999.\n",
      ".. [NR] William H. Press et. al., \"Numerical Recipes. The Art of Scientific\n",
      "        Computing. 3rd edition\", Sec. 5.7.\n",
      ".. [Byrd] R. H. Byrd, R. B. Schnabel and G. A. Shultz, \"Approximate\n",
      "          solution of the trust region problem by minimization over\n",
      "          two-dimensional subspaces\", Math. Programming, 40, pp. 247-263,\n",
      "          1988.\n",
      ".. [Curtis] A. Curtis, M. J. D. Powell, and J. Reid, \"On the estimation of\n",
      "            sparse Jacobian matrices\", Journal of the Institute of\n",
      "            Mathematics and its Applications, 13, pp. 117-120, 1974.\n",
      ".. [JJMore] J. J. More, \"The Levenberg-Marquardt Algorithm: Implementation\n",
      "            and Theory,\" Numerical Analysis, ed. G. A. Watson, Lecture\n",
      "            Notes in Mathematics 630, Springer Verlag, pp. 105-116, 1977.\n",
      ".. [Voglis] C. Voglis and I. E. Lagaris, \"A Rectangular Trust Region\n",
      "            Dogleg Approach for Unconstrained and Bound Constrained\n",
      "            Nonlinear Optimization\", WSEAS International Conference on\n",
      "            Applied Mathematics, Corfu, Greece, 2004.\n",
      ".. [NumOpt] J. Nocedal and S. J. Wright, \"Numerical optimization,\n",
      "            2nd edition\", Chapter 4.\n",
      ".. [BA] B. Triggs et. al., \"Bundle Adjustment - A Modern Synthesis\",\n",
      "        Proceedings of the International Workshop on Vision Algorithms:\n",
      "        Theory and Practice, pp. 298-372, 1999.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "In this example we find a minimum of the Rosenbrock function without bounds\n",
      "on independent variables.\n",
      "\n",
      ">>> import numpy as np\n",
      ">>> def fun_rosenbrock(x):\n",
      "...     return np.array([10 * (x[1] - x[0]**2), (1 - x[0])])\n",
      "\n",
      "Notice that we only provide the vector of the residuals. The algorithm\n",
      "constructs the cost function as a sum of squares of the residuals, which\n",
      "gives the Rosenbrock function. The exact minimum is at ``x = [1.0, 1.0]``.\n",
      "\n",
      ">>> from scipy.optimize import least_squares\n",
      ">>> x0_rosenbrock = np.array([2, 2])\n",
      ">>> res_1 = least_squares(fun_rosenbrock, x0_rosenbrock)\n",
      ">>> res_1.x\n",
      "array([ 1.,  1.])\n",
      ">>> res_1.cost\n",
      "9.8669242910846867e-30\n",
      ">>> res_1.optimality\n",
      "8.8928864934219529e-14\n",
      "\n",
      "We now constrain the variables, in such a way that the previous solution\n",
      "becomes infeasible. Specifically, we require that ``x[1] >= 1.5``, and\n",
      "``x[0]`` left unconstrained. To this end, we specify the `bounds` parameter\n",
      "to `least_squares` in the form ``bounds=([-np.inf, 1.5], np.inf)``.\n",
      "\n",
      "We also provide the analytic Jacobian:\n",
      "\n",
      ">>> def jac_rosenbrock(x):\n",
      "...     return np.array([\n",
      "...         [-20 * x[0], 10],\n",
      "...         [-1, 0]])\n",
      "\n",
      "Putting this all together, we see that the new solution lies on the bound:\n",
      "\n",
      ">>> res_2 = least_squares(fun_rosenbrock, x0_rosenbrock, jac_rosenbrock,\n",
      "...                       bounds=([-np.inf, 1.5], np.inf))\n",
      ">>> res_2.x\n",
      "array([ 1.22437075,  1.5       ])\n",
      ">>> res_2.cost\n",
      "0.025213093946805685\n",
      ">>> res_2.optimality\n",
      "1.5885401433157753e-07\n",
      "\n",
      "Now we solve a system of equations (i.e., the cost function should be zero\n",
      "at a minimum) for a Broyden tridiagonal vector-valued function of 100000\n",
      "variables:\n",
      "\n",
      ">>> def fun_broyden(x):\n",
      "...     f = (3 - x) * x + 1\n",
      "...     f[1:] -= x[:-1]\n",
      "...     f[:-1] -= 2 * x[1:]\n",
      "...     return f\n",
      "\n",
      "The corresponding Jacobian matrix is sparse. We tell the algorithm to\n",
      "estimate it by finite differences and provide the sparsity structure of\n",
      "Jacobian to significantly speed up this process.\n",
      "\n",
      ">>> from scipy.sparse import lil_matrix\n",
      ">>> def sparsity_broyden(n):\n",
      "...     sparsity = lil_matrix((n, n), dtype=int)\n",
      "...     i = np.arange(n)\n",
      "...     sparsity[i, i] = 1\n",
      "...     i = np.arange(1, n)\n",
      "...     sparsity[i, i - 1] = 1\n",
      "...     i = np.arange(n - 1)\n",
      "...     sparsity[i, i + 1] = 1\n",
      "...     return sparsity\n",
      "...\n",
      ">>> n = 100000\n",
      ">>> x0_broyden = -np.ones(n)\n",
      "...\n",
      ">>> res_3 = least_squares(fun_broyden, x0_broyden,\n",
      "...                       jac_sparsity=sparsity_broyden(n))\n",
      ">>> res_3.cost\n",
      "4.5687069299604613e-23\n",
      ">>> res_3.optimality\n",
      "1.1650454296851518e-11\n",
      "\n",
      "Let's also solve a curve fitting problem using robust loss function to\n",
      "take care of outliers in the data. Define the model function as\n",
      "``y = a + b * exp(c * t)``, where t is a predictor variable, y is an\n",
      "observation and a, b, c are parameters to estimate.\n",
      "\n",
      "First, define the function which generates the data with noise and\n",
      "outliers, define the model parameters, and generate data:\n",
      "\n",
      ">>> from numpy.random import default_rng\n",
      ">>> rng = default_rng()\n",
      ">>> def gen_data(t, a, b, c, noise=0., n_outliers=0, seed=None):\n",
      "...     rng = default_rng(seed)\n",
      "...\n",
      "...     y = a + b * np.exp(t * c)\n",
      "...\n",
      "...     error = noise * rng.standard_normal(t.size)\n",
      "...     outliers = rng.integers(0, t.size, n_outliers)\n",
      "...     error[outliers] *= 10\n",
      "...\n",
      "...     return y + error\n",
      "...\n",
      ">>> a = 0.5\n",
      ">>> b = 2.0\n",
      ">>> c = -1\n",
      ">>> t_min = 0\n",
      ">>> t_max = 10\n",
      ">>> n_points = 15\n",
      "...\n",
      ">>> t_train = np.linspace(t_min, t_max, n_points)\n",
      ">>> y_train = gen_data(t_train, a, b, c, noise=0.1, n_outliers=3)\n",
      "\n",
      "Define function for computing residuals and initial estimate of\n",
      "parameters.\n",
      "\n",
      ">>> def fun(x, t, y):\n",
      "...     return x[0] + x[1] * np.exp(x[2] * t) - y\n",
      "...\n",
      ">>> x0 = np.array([1.0, 1.0, 0.0])\n",
      "\n",
      "Compute a standard least-squares solution:\n",
      "\n",
      ">>> res_lsq = least_squares(fun, x0, args=(t_train, y_train))\n",
      "\n",
      "Now compute two solutions with two different robust loss functions. The\n",
      "parameter `f_scale` is set to 0.1, meaning that inlier residuals should\n",
      "not significantly exceed 0.1 (the noise level used).\n",
      "\n",
      ">>> res_soft_l1 = least_squares(fun, x0, loss='soft_l1', f_scale=0.1,\n",
      "...                             args=(t_train, y_train))\n",
      ">>> res_log = least_squares(fun, x0, loss='cauchy', f_scale=0.1,\n",
      "...                         args=(t_train, y_train))\n",
      "\n",
      "And, finally, plot all the curves. We see that by selecting an appropriate\n",
      "`loss`  we can get estimates close to optimal even in the presence of\n",
      "strong outliers. But keep in mind that generally it is recommended to try\n",
      "'soft_l1' or 'huber' losses first (if at all necessary) as the other two\n",
      "options may cause difficulties in optimization process.\n",
      "\n",
      ">>> t_test = np.linspace(t_min, t_max, n_points * 10)\n",
      ">>> y_true = gen_data(t_test, a, b, c)\n",
      ">>> y_lsq = gen_data(t_test, *res_lsq.x)\n",
      ">>> y_soft_l1 = gen_data(t_test, *res_soft_l1.x)\n",
      ">>> y_log = gen_data(t_test, *res_log.x)\n",
      "...\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> plt.plot(t_train, y_train, 'o')\n",
      ">>> plt.plot(t_test, y_true, 'k', linewidth=2, label='true')\n",
      ">>> plt.plot(t_test, y_lsq, label='linear loss')\n",
      ">>> plt.plot(t_test, y_soft_l1, label='soft_l1 loss')\n",
      ">>> plt.plot(t_test, y_log, label='cauchy loss')\n",
      ">>> plt.xlabel(\"t\")\n",
      ">>> plt.ylabel(\"y\")\n",
      ">>> plt.legend()\n",
      ">>> plt.show()\n",
      "\n",
      "In the next example, we show how complex-valued residual functions of\n",
      "complex variables can be optimized with ``least_squares()``. Consider the\n",
      "following function:\n",
      "\n",
      ">>> def f(z):\n",
      "...     return z - (0.5 + 0.5j)\n",
      "\n",
      "We wrap it into a function of real variables that returns real residuals\n",
      "by simply handling the real and imaginary parts as independent variables:\n",
      "\n",
      ">>> def f_wrap(x):\n",
      "...     fx = f(x[0] + 1j*x[1])\n",
      "...     return np.array([fx.real, fx.imag])\n",
      "\n",
      "Thus, instead of the original m-D complex function of n complex\n",
      "variables we optimize a 2m-D real function of 2n real variables:\n",
      "\n",
      ">>> from scipy.optimize import least_squares\n",
      ">>> res_wrapped = least_squares(f_wrap, (0.1, 0.1), bounds=([0, 0], [1, 1]))\n",
      ">>> z = res_wrapped.x[0] + res_wrapped.x[1]*1j\n",
      ">>> z\n",
      "(0.49999999999925893+0.49999999999925893j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4649/3432953689.py:2: DeprecationWarning: scipy.info is deprecated and will be removed in SciPy 2.0.0, use numpy.info instead\n",
      "  scipy.info(scipy.optimize.least_squares)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.info(scipy.optimize.least_squares)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性最小二乘法+多项式拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [[  1   1   1]\n",
      " [  4   2   1]\n",
      " [  9   3   1]\n",
      " [ 16   4   1]\n",
      " [ 25   5   1]\n",
      " [ 36   6   1]\n",
      " [ 49   7   1]\n",
      " [ 64   8   1]\n",
      " [ 81   9   1]\n",
      " [100  10   1]\n",
      " [121  11   1]\n",
      " [144  12   1]\n",
      " [169  13   1]\n",
      " [196  14   1]\n",
      " [225  15   1]\n",
      " [256  16   1]]\n",
      "二次多项式拟合函数：y = -0.0445 * t^2 1.0660 * t^1 4.3875 * t^0\n",
      "拟合的残差平方和： 4.907064499299699\n",
      "A = [[   1    1    1]\n",
      " [   8    4    2]\n",
      " [  27    9    3]\n",
      " [  64   16    4]\n",
      " [ 125   25    5]\n",
      " [ 216   36    6]\n",
      " [ 343   49    7]\n",
      " [ 512   64    8]\n",
      " [ 729   81    9]\n",
      " [1000  100   10]\n",
      " [1331  121   11]\n",
      " [1728  144   12]\n",
      " [2197  169   13]\n",
      " [2744  196   14]\n",
      " [3375  225   15]\n",
      " [4096  256   16]]\n",
      "经过坐标原点的三次多项式拟合函数：y = 0.0112 * t^3 -0.3440 * t^2 3.3419 * t^1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 实验数据\n",
    "t = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])\n",
    "y = np.array([4.00, 6.40, 8.00, 8.80, 9.22, 9.50, 9.70, 9.86, 10.00, 10.20, 10.32, 10.42, 10.50, 10.55, 10.58, 10.60])\n",
    "\n",
    "# 二次多项式拟合\n",
    "n = 2  # 多项式的阶数\n",
    "A = np.vander(t, n + 1)  # 构建 Vandermonde 矩阵\n",
    "\n",
    "print(f\"A = {A}\")\n",
    "\n",
    "coefficients, residuals, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "\n",
    "# 残差平方和\n",
    "Q = residuals[0]\n",
    "\n",
    "# 输出二次多项式拟合函数和残差平方和\n",
    "print(\"二次多项式拟合函数：y =\", end=\" \")\n",
    "for i in range(n + 1):\n",
    "    print(f\"{coefficients[i]:.4f} * t^{n - i}\", end=\" \" if i < n else \"\\n\")\n",
    "print(\"拟合的残差平方和：\", Q)\n",
    "\n",
    "# 三次多项式拟合（经过坐标原点）\n",
    "A = np.multiply(A, t[:, np.newaxis])  # 将矩阵的每一列与向量 t 对应元素相乘\n",
    "\n",
    "print(f\"A = {A}\")\n",
    "\n",
    "coefficients, residuals, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "\n",
    "# 输出经过坐标原点的三次多项式拟合函数\n",
    "print(\"经过坐标原点的三次多项式拟合函数：y =\", end=\" \")\n",
    "for i in range(n + 1):\n",
    "    print(f\"{coefficients[i]:.4f} * t^{n - i + 1}\", end=\" \" if i < n else \"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.00010907 3.61647546]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "t_data = np.array([0.3, 0.5, 1.0, 2.0, 4.0, 7.0])\n",
    "v_data = np.array([5.6873, 6.1434, 7.1633, 8.8626, 11.0328, 12.6962])\n",
    "\n",
    "log_v_data = np.log(14 - v_data)\n",
    "\n",
    "def v_func(t, tau, v0):\n",
    "    return np.log(14-v0) - t / tau\n",
    "\n",
    "popt, pcov = curve_fit(v_func, t_data, log_v_data, p0=[1, 0])\n",
    "\n",
    "tau = popt[0]\n",
    "v0 = popt[1]\n",
    "\n",
    "\n",
    "# 模板二\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "list_t = np.array([0.3, 0.5, 1.0, 2.0, 4.0, 7.0])\n",
    "v_data = np.array([5.6873, 6.1434, 7.1633, 8.8626, 11.0328, 12.6962])\n",
    "\n",
    "def objective(x):\n",
    "    v0 = x[0]\n",
    "    tao = x[1]\n",
    "    v = 14\n",
    "    F = np.zeros(len(list_t))\n",
    "    for i in range(len(list_t)):\n",
    "        t = list_t[i]\n",
    "        vt = v_data[i]\n",
    "        F[i] = np.log(v -vt) - np.log(v - v0) + t / tao\n",
    "    return F\n",
    "\n",
    "x0 = [1, 1]\n",
    "#! x0 的选取影响很大，但是 tau 确实不该取 0\n",
    "res = least_squares(objective, x0)\n",
    "print(res.x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性规划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None,\n",
      "         method='highs', callback=None, options=None, x0=None,\n",
      "         integrality=None)\n",
      "\n",
      "Linear programming: minimize a linear objective function subject to linear\n",
      "equality and inequality constraints.\n",
      "\n",
      "Linear programming solves problems of the following form:\n",
      "\n",
      ".. math::\n",
      "\n",
      "    \\min_x \\ & c^T x \\\\\n",
      "    \\mbox{such that} \\ & A_{ub} x \\leq b_{ub},\\\\\n",
      "    & A_{eq} x = b_{eq},\\\\\n",
      "    & l \\leq x \\leq u ,\n",
      "\n",
      "where :math:`x` is a vector of decision variables; :math:`c`,\n",
      ":math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and\n",
      ":math:`A_{ub}` and :math:`A_{eq}` are matrices.\n",
      "\n",
      "Alternatively, that's:\n",
      "\n",
      "minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "such that::\n",
      "\n",
      "    A_ub @ x <= b_ub\n",
      "    A_eq @ x == b_eq\n",
      "    lb <= x <= ub\n",
      "\n",
      "Note that by default ``lb = 0`` and ``ub = None`` unless specified with\n",
      "``bounds``.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "c : 1-D array\n",
      "    The coefficients of the linear objective function to be minimized.\n",
      "A_ub : 2-D array, optional\n",
      "    The inequality constraint matrix. Each row of ``A_ub`` specifies the\n",
      "    coefficients of a linear inequality constraint on ``x``.\n",
      "b_ub : 1-D array, optional\n",
      "    The inequality constraint vector. Each element represents an\n",
      "    upper bound on the corresponding value of ``A_ub @ x``.\n",
      "A_eq : 2-D array, optional\n",
      "    The equality constraint matrix. Each row of ``A_eq`` specifies the\n",
      "    coefficients of a linear equality constraint on ``x``.\n",
      "b_eq : 1-D array, optional\n",
      "    The equality constraint vector. Each element of ``A_eq @ x`` must equal\n",
      "    the corresponding element of ``b_eq``.\n",
      "bounds : sequence, optional\n",
      "    A sequence of ``(min, max)`` pairs for each element in ``x``, defining\n",
      "    the minimum and maximum values of that decision variable. Use ``None``\n",
      "    to indicate that there is no bound. By default, bounds are\n",
      "    ``(0, None)`` (all decision variables are non-negative).\n",
      "    If a single tuple ``(min, max)`` is provided, then ``min`` and\n",
      "    ``max`` will serve as bounds for all decision variables.\n",
      "method : str, optional\n",
      "    The algorithm used to solve the standard form problem.\n",
      "    :ref:`'highs' <optimize.linprog-highs>` (default),\n",
      "    :ref:`'highs-ds' <optimize.linprog-highs-ds>`,\n",
      "    :ref:`'highs-ipm' <optimize.linprog-highs-ipm>`,\n",
      "    :ref:`'interior-point' <optimize.linprog-interior-point>` (legacy),\n",
      "    :ref:`'revised simplex' <optimize.linprog-revised_simplex>` (legacy),\n",
      "    and\n",
      "    :ref:`'simplex' <optimize.linprog-simplex>` (legacy) are supported.\n",
      "    The legacy methods are deprecated and will be removed in SciPy 1.11.0.\n",
      "callback : callable, optional\n",
      "    If a callback function is provided, it will be called at least once per\n",
      "    iteration of the algorithm. The callback function must accept a single\n",
      "    `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "\n",
      "    x : 1-D array\n",
      "        The current solution vector.\n",
      "    fun : float\n",
      "        The current value of the objective function ``c @ x``.\n",
      "    success : bool\n",
      "        ``True`` when the algorithm has completed successfully.\n",
      "    slack : 1-D array\n",
      "        The (nominally positive) values of the slack,\n",
      "        ``b_ub - A_ub @ x``.\n",
      "    con : 1-D array\n",
      "        The (nominally zero) residuals of the equality constraints,\n",
      "        ``b_eq - A_eq @ x``.\n",
      "    phase : int\n",
      "        The phase of the algorithm being executed.\n",
      "    status : int\n",
      "        An integer representing the status of the algorithm.\n",
      "\n",
      "        ``0`` : Optimization proceeding nominally.\n",
      "\n",
      "        ``1`` : Iteration limit reached.\n",
      "\n",
      "        ``2`` : Problem appears to be infeasible.\n",
      "\n",
      "        ``3`` : Problem appears to be unbounded.\n",
      "\n",
      "        ``4`` : Numerical difficulties encountered.\n",
      "\n",
      "        nit : int\n",
      "            The current iteration number.\n",
      "        message : str\n",
      "            A string descriptor of the algorithm status.\n",
      "\n",
      "    Callback functions are not currently supported by the HiGHS methods.\n",
      "\n",
      "options : dict, optional\n",
      "    A dictionary of solver options. All methods accept the following\n",
      "    options:\n",
      "\n",
      "    maxiter : int\n",
      "        Maximum number of iterations to perform.\n",
      "        Default: see method-specific documentation.\n",
      "    disp : bool\n",
      "        Set to ``True`` to print convergence messages.\n",
      "        Default: ``False``.\n",
      "    presolve : bool\n",
      "        Set to ``False`` to disable automatic presolve.\n",
      "        Default: ``True``.\n",
      "\n",
      "    All methods except the HiGHS solvers also accept:\n",
      "\n",
      "    tol : float\n",
      "        A tolerance which determines when a residual is \"close enough\" to\n",
      "        zero to be considered exactly zero.\n",
      "    autoscale : bool\n",
      "        Set to ``True`` to automatically perform equilibration.\n",
      "        Consider using this option if the numerical values in the\n",
      "        constraints are separated by several orders of magnitude.\n",
      "        Default: ``False``.\n",
      "    rr : bool\n",
      "        Set to ``False`` to disable automatic redundancy removal.\n",
      "        Default: ``True``.\n",
      "    rr_method : string\n",
      "        Method used to identify and remove redundant rows from the\n",
      "        equality constraint matrix after presolve. For problems with\n",
      "        dense input, the available methods for redundancy removal are:\n",
      "\n",
      "        \"SVD\":\n",
      "            Repeatedly performs singular value decomposition on\n",
      "            the matrix, detecting redundant rows based on nonzeros\n",
      "            in the left singular vectors that correspond with\n",
      "            zero singular values. May be fast when the matrix is\n",
      "            nearly full rank.\n",
      "        \"pivot\":\n",
      "            Uses the algorithm presented in [5]_ to identify\n",
      "            redundant rows.\n",
      "        \"ID\":\n",
      "            Uses a randomized interpolative decomposition.\n",
      "            Identifies columns of the matrix transpose not used in\n",
      "            a full-rank interpolative decomposition of the matrix.\n",
      "        None:\n",
      "            Uses \"svd\" if the matrix is nearly full rank, that is,\n",
      "            the difference between the matrix rank and the number\n",
      "            of rows is less than five. If not, uses \"pivot\". The\n",
      "            behavior of this default is subject to change without\n",
      "            prior notice.\n",
      "\n",
      "        Default: None.\n",
      "        For problems with sparse input, this option is ignored, and the\n",
      "        pivot-based algorithm presented in [5]_ is used.\n",
      "\n",
      "    For method-specific options, see\n",
      "    :func:`show_options('linprog') <show_options>`.\n",
      "\n",
      "x0 : 1-D array, optional\n",
      "    Guess values of the decision variables, which will be refined by\n",
      "    the optimization algorithm. This argument is currently used only by the\n",
      "    'revised simplex' method, and can only be used if `x0` represents a\n",
      "    basic feasible solution.\n",
      "\n",
      "integrality : 1-D array or int, optional\n",
      "    Indicates the type of integrality constraint on each decision variable.\n",
      "\n",
      "    ``0`` : Continuous variable; no integrality constraint.\n",
      "\n",
      "    ``1`` : Integer variable; decision variable must be an integer\n",
      "    within `bounds`.\n",
      "\n",
      "    ``2`` : Semi-continuous variable; decision variable must be within\n",
      "    `bounds` or take value ``0``.\n",
      "\n",
      "    ``3`` : Semi-integer variable; decision variable must be an integer\n",
      "    within `bounds` or take value ``0``.\n",
      "\n",
      "    By default, all variables are continuous.\n",
      "\n",
      "    For mixed integrality constraints, supply an array of shape `c.shape`.\n",
      "    To infer a constraint on each decision variable from shorter inputs,\n",
      "    the argument will be broadcasted to `c.shape` using `np.broadcast_to`.\n",
      "\n",
      "    This argument is currently used only by the ``'highs'`` method and\n",
      "    ignored otherwise.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "res : OptimizeResult\n",
      "    A :class:`scipy.optimize.OptimizeResult` consisting of the fields\n",
      "    below. Note that the return types of the fields may depend on whether\n",
      "    the optimization was successful, therefore it is recommended to check\n",
      "    `OptimizeResult.status` before relying on the other fields:\n",
      "\n",
      "    x : 1-D array\n",
      "        The values of the decision variables that minimizes the\n",
      "        objective function while satisfying the constraints.\n",
      "    fun : float\n",
      "        The optimal value of the objective function ``c @ x``.\n",
      "    slack : 1-D array\n",
      "        The (nominally positive) values of the slack variables,\n",
      "        ``b_ub - A_ub @ x``.\n",
      "    con : 1-D array\n",
      "        The (nominally zero) residuals of the equality constraints,\n",
      "        ``b_eq - A_eq @ x``.\n",
      "    success : bool\n",
      "        ``True`` when the algorithm succeeds in finding an optimal\n",
      "        solution.\n",
      "    status : int\n",
      "        An integer representing the exit status of the algorithm.\n",
      "\n",
      "        ``0`` : Optimization terminated successfully.\n",
      "\n",
      "        ``1`` : Iteration limit reached.\n",
      "\n",
      "        ``2`` : Problem appears to be infeasible.\n",
      "\n",
      "        ``3`` : Problem appears to be unbounded.\n",
      "\n",
      "        ``4`` : Numerical difficulties encountered.\n",
      "\n",
      "    nit : int\n",
      "        The total number of iterations performed in all phases.\n",
      "    message : str\n",
      "        A string descriptor of the exit status of the algorithm.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "show_options : Additional options accepted by the solvers.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "This section describes the available solvers that can be selected by the\n",
      "'method' parameter.\n",
      "\n",
      "`'highs-ds'` and\n",
      "`'highs-ipm'` are interfaces to the\n",
      "HiGHS simplex and interior-point method solvers [13]_, respectively.\n",
      "`'highs'` (default) chooses between\n",
      "the two automatically. These are the fastest linear\n",
      "programming solvers in SciPy, especially for large, sparse problems;\n",
      "which of these two is faster is problem-dependent.\n",
      "The other solvers (`'interior-point'`, `'revised simplex'`, and\n",
      "`'simplex'`) are legacy methods and will be removed in SciPy 1.11.0.\n",
      "\n",
      "Method *highs-ds* is a wrapper of the C++ high performance dual\n",
      "revised simplex implementation (HSOL) [13]_, [14]_. Method *highs-ipm*\n",
      "is a wrapper of a C++ implementation of an **i**\\ nterior-\\ **p**\\ oint\n",
      "**m**\\ ethod [13]_; it features a crossover routine, so it is as accurate\n",
      "as a simplex solver. Method *highs* chooses between the two automatically.\n",
      "For new code involving `linprog`, we recommend explicitly choosing one of\n",
      "these three method values.\n",
      "\n",
      ".. versionadded:: 1.6.0\n",
      "\n",
      "Method *interior-point* uses the primal-dual path following algorithm\n",
      "as outlined in [4]_. This algorithm supports sparse constraint matrices and\n",
      "is typically faster than the simplex methods, especially for large, sparse\n",
      "problems. Note, however, that the solution returned may be slightly less\n",
      "accurate than those of the simplex methods and will not, in general,\n",
      "correspond with a vertex of the polytope defined by the constraints.\n",
      "\n",
      ".. versionadded:: 1.0.0\n",
      "\n",
      "Method *revised simplex* uses the revised simplex method as described in\n",
      "[9]_, except that a factorization [11]_ of the basis matrix, rather than\n",
      "its inverse, is efficiently maintained and used to solve the linear systems\n",
      "at each iteration of the algorithm.\n",
      "\n",
      ".. versionadded:: 1.3.0\n",
      "\n",
      "Method *simplex* uses a traditional, full-tableau implementation of\n",
      "Dantzig's simplex algorithm [1]_, [2]_ (*not* the\n",
      "Nelder-Mead simplex). This algorithm is included for backwards\n",
      "compatibility and educational purposes.\n",
      "\n",
      ".. versionadded:: 0.15.0\n",
      "\n",
      "Before applying *interior-point*, *revised simplex*, or *simplex*,\n",
      "a presolve procedure based on [8]_ attempts\n",
      "to identify trivial infeasibilities, trivial unboundedness, and potential\n",
      "problem simplifications. Specifically, it checks for:\n",
      "\n",
      "- rows of zeros in ``A_eq`` or ``A_ub``, representing trivial constraints;\n",
      "- columns of zeros in ``A_eq`` `and` ``A_ub``, representing unconstrained\n",
      "  variables;\n",
      "- column singletons in ``A_eq``, representing fixed variables; and\n",
      "- column singletons in ``A_ub``, representing simple bounds.\n",
      "\n",
      "If presolve reveals that the problem is unbounded (e.g. an unconstrained\n",
      "and unbounded variable has negative cost) or infeasible (e.g., a row of\n",
      "zeros in ``A_eq`` corresponds with a nonzero in ``b_eq``), the solver\n",
      "terminates with the appropriate status code. Note that presolve terminates\n",
      "as soon as any sign of unboundedness is detected; consequently, a problem\n",
      "may be reported as unbounded when in reality the problem is infeasible\n",
      "(but infeasibility has not been detected yet). Therefore, if it is\n",
      "important to know whether the problem is actually infeasible, solve the\n",
      "problem again with option ``presolve=False``.\n",
      "\n",
      "If neither infeasibility nor unboundedness are detected in a single pass\n",
      "of the presolve, bounds are tightened where possible and fixed\n",
      "variables are removed from the problem. Then, linearly dependent rows\n",
      "of the ``A_eq`` matrix are removed, (unless they represent an\n",
      "infeasibility) to avoid numerical difficulties in the primary solve\n",
      "routine. Note that rows that are nearly linearly dependent (within a\n",
      "prescribed tolerance) may also be removed, which can change the optimal\n",
      "solution in rare cases. If this is a concern, eliminate redundancy from\n",
      "your problem formulation and run with option ``rr=False`` or\n",
      "``presolve=False``.\n",
      "\n",
      "Several potential improvements can be made here: additional presolve\n",
      "checks outlined in [8]_ should be implemented, the presolve routine should\n",
      "be run multiple times (until no further simplifications can be made), and\n",
      "more of the efficiency improvements from [5]_ should be implemented in the\n",
      "redundancy removal routines.\n",
      "\n",
      "After presolve, the problem is transformed to standard form by converting\n",
      "the (tightened) simple bounds to upper bound constraints, introducing\n",
      "non-negative slack variables for inequality constraints, and expressing\n",
      "unbounded variables as the difference between two non-negative variables.\n",
      "Optionally, the problem is automatically scaled via equilibration [12]_.\n",
      "The selected algorithm solves the standard form problem, and a\n",
      "postprocessing routine converts the result to a solution to the original\n",
      "problem.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "       Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "       1963\n",
      ".. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "       Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      ".. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "       Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      ".. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "       optimizer for linear programming: an implementation of the\n",
      "       homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "       2000. 197-232.\n",
      ".. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n",
      "       large-scale linear programming.\" Optimization Methods and Software\n",
      "       6.3 (1995): 219-227.\n",
      ".. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "       Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "       March 2004. Available 2/25/2017 at\n",
      "       https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      ".. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n",
      "       Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n",
      "       http://www.4er.org/CourseNotes/Book%20B/B-III.pdf\n",
      ".. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "       programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      ".. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "       programming.\" Athena Scientific 1 (1997): 997.\n",
      ".. [10] Andersen, Erling D., et al. Implementation of interior point\n",
      "        methods for large scale linear programming. HEC/Universite de\n",
      "        Geneve, 1996.\n",
      ".. [11] Bartels, Richard H. \"A stabilization of the simplex method.\"\n",
      "        Journal in  Numerische Mathematik 16.5 (1971): 414-434.\n",
      ".. [12] Tomlin, J. A. \"On scaling linear programming problems.\"\n",
      "        Mathematical Programming Study 4 (1975): 146-166.\n",
      ".. [13] Huangfu, Q., Galabova, I., Feldmeier, M., and Hall, J. A. J.\n",
      "        \"HiGHS - high performance software for linear optimization.\"\n",
      "        https://highs.dev/\n",
      ".. [14] Huangfu, Q. and Hall, J. A. J. \"Parallelizing the dual revised\n",
      "        simplex method.\" Mathematical Programming Computation, 10 (1),\n",
      "        119-142, 2018. DOI: 10.1007/s12532-017-0130-5\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Consider the following problem:\n",
      "\n",
      ".. math::\n",
      "\n",
      "    \\min_{x_0, x_1} \\ -x_0 + 4x_1 & \\\\\n",
      "    \\mbox{such that} \\ -3x_0 + x_1 & \\leq 6,\\\\\n",
      "    -x_0 - 2x_1 & \\geq -4,\\\\\n",
      "    x_1 & \\geq -3.\n",
      "\n",
      "The problem is not presented in the form accepted by `linprog`. This is\n",
      "easily remedied by converting the \"greater than\" inequality\n",
      "constraint to a \"less than\" inequality constraint by\n",
      "multiplying both sides by a factor of :math:`-1`. Note also that the last\n",
      "constraint is really the simple bound :math:`-3 \\leq x_1 \\leq \\infty`.\n",
      "Finally, since there are no bounds on :math:`x_0`, we must explicitly\n",
      "specify the bounds :math:`-\\infty \\leq x_0 \\leq \\infty`, as the\n",
      "default is for variables to be non-negative. After collecting coeffecients\n",
      "into arrays and tuples, the input for this problem is:\n",
      "\n",
      ">>> from scipy.optimize import linprog\n",
      ">>> c = [-1, 4]\n",
      ">>> A = [[-3, 1], [1, 2]]\n",
      ">>> b = [6, 4]\n",
      ">>> x0_bounds = (None, None)\n",
      ">>> x1_bounds = (-3, None)\n",
      ">>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds])\n",
      ">>> res.fun\n",
      "-22.0\n",
      ">>> res.x\n",
      "array([10., -3.])\n",
      ">>> res.message\n",
      "'Optimization terminated successfully. (HiGHS Status 7: Optimal)'\n",
      "\n",
      "The marginals (AKA dual values / shadow prices / Lagrange multipliers)\n",
      "and residuals (slacks) are also available.\n",
      "\n",
      ">>> res.ineqlin\n",
      "  residual: [ 3.900e+01  0.000e+00]\n",
      " marginals: [-0.000e+00 -1.000e+00]\n",
      "\n",
      "For example, because the marginal associated with the second inequality\n",
      "constraint is -1, we expect the optimal value of the objective function\n",
      "to decrease by ``eps`` if we add a small amount ``eps`` to the right hand\n",
      "side of the second inequality constraint:\n",
      "\n",
      ">>> eps = 0.05\n",
      ">>> b[1] += eps\n",
      ">>> linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds]).fun\n",
      "-22.05\n",
      "\n",
      "Also, because the residual on the first inequality constraint is 39, we\n",
      "can decrease the right hand side of the first constraint by 39 without\n",
      "affecting the optimal solution.\n",
      "\n",
      ">>> b = [6, 4]  # reset to original values\n",
      ">>> b[0] -= 39\n",
      ">>> linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds]).fun\n",
      "-22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_722/2196696522.py:2: DeprecationWarning: scipy.info is deprecated and will be removed in SciPy 2.0.0, use numpy.info instead\n",
      "  scipy.info(linprog)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.info(linprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
      "        success: True\n",
      "         status: 0\n",
      "            fun: -3070.0\n",
      "              x: [ 1.000e+01  4.500e+01]\n",
      "            nit: 0\n",
      "          lower:  residual: [ 1.000e+01  4.500e+01]\n",
      "                 marginals: [ 0.000e+00  0.000e+00]\n",
      "          upper:  residual: [ 4.500e+01  1.000e+01]\n",
      "                 marginals: [ 0.000e+00  0.000e+00]\n",
      "          eqlin:  residual: [ 0.000e+00]\n",
      "                 marginals: [-3.400e+01]\n",
      "        ineqlin:  residual: [ 5.000e+01  0.000e+00]\n",
      "                 marginals: [-0.000e+00 -2.500e+00]\n",
      " mip_node_count: 0\n",
      " mip_dual_bound: 0.0\n",
      "        mip_gap: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# Define the objective function\n",
    "c = np.array([-64, -54])\n",
    "\n",
    "# Define the inequality constraints\n",
    "A_ub = np.array([[3, 0], [12, 8]])\n",
    "b_ub = np.array([80, 480])\n",
    "\n",
    "# Define the equality constraints\n",
    "A_eq = np.array([[1, 1]])\n",
    "b_eq = np.array([55])\n",
    "\n",
    "# Define the bounds\n",
    "bounds = [(0, 55), (0, 55)]\n",
    "\n",
    "# Call the linprog function\n",
    "res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小总成本: 2602000.0\n",
      "甲饮料厂生产A饮料: 0.0 t\n",
      "甲饮料厂生产B饮料: 1520.0 t\n",
      "乙饮料厂生产A饮料: 1000.0 t\n",
      "乙饮料厂生产B饮料: 80.0 t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# 目标函数系数\n",
    "c = np.array([1000, 1100, 850, 1000])\n",
    "\n",
    "# 不等式约束矩阵和右侧常数\n",
    "A = np.array([\n",
    "    [5, 4, 0, 0],\n",
    "    [0, 0, 2, 5]\n",
    "])\n",
    "b_ub = np.array([200 * 40, 120 * 20])\n",
    "\n",
    "# 等式约束矩阵和右侧常数\n",
    "A_eq = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
    "b_eq = np.array([1000, 1600])\n",
    "\n",
    "# 变量取值范围\n",
    "x_bounds = [(0, None), (0, None), (0, None), (0, None)]\n",
    "\n",
    "# 使用线性规划求解\n",
    "result = linprog(c, A_ub=A, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=x_bounds, method='highs')\n",
    "\n",
    "# 输出结果\n",
    "print(\"最小总成本:\", result.fun)\n",
    "print(\"甲饮料厂生产A饮料:\", result.x[0], \"t\")\n",
    "print(\"甲饮料厂生产B饮料:\", result.x[1], \"t\")\n",
    "print(\"乙饮料厂生产A饮料:\", result.x[2], \"t\")\n",
    "print(\"乙饮料厂生产B饮料:\", result.x[3], \"t\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变量置为常数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       message: The problem is infeasible. (HiGHS Status 8: model_status is Infeasible; primal_status is At lower/fixed bound)\n",
      "       success: False\n",
      "        status: 2\n",
      "           fun: None\n",
      "             x: None\n",
      "           nit: 0\n",
      "         lower:  residual: None\n",
      "                marginals: None\n",
      "         upper:  residual: None\n",
      "                marginals: None\n",
      "         eqlin:  residual: None\n",
      "                marginals: None\n",
      "       ineqlin:  residual: None\n",
      "                marginals: None\n",
      "最小总成本: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb Cell 36\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# 输出结果\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m最小总成本:\u001b[39m\u001b[39m\"\u001b[39m, result\u001b[39m.\u001b[39mfun)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m甲饮料厂生产A饮料:\u001b[39m\u001b[39m\"\u001b[39m, result\u001b[39m.\u001b[39;49mx[\u001b[39m0\u001b[39;49m], \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m甲饮料厂生产B饮料:\u001b[39m\u001b[39m\"\u001b[39m, result\u001b[39m.\u001b[39mx[\u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/kidrain61/code/courses/courses-TYX-THU-CST/ME-XJX-2023S/Exam.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# print(\"乙饮料厂生产A饮料:\", result.x[2], \"t\")\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 此处去掉 x_3\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# 目标函数系数\n",
    "# c = np.array([1000, 1100, 850, 1000])\n",
    "\n",
    "c = np.array([1000, 1100, 1000])\n",
    "\n",
    "\n",
    "# 不等式约束矩阵和右侧常数\n",
    "# A = np.array([\n",
    "#     [5, 4, 0, 0],\n",
    "#     [0, 0, 2, 5]\n",
    "# ])\n",
    "\n",
    "A = np.array([\n",
    "    [5, 4, 0],\n",
    "    [0, 0, 5]\n",
    "])\n",
    "\n",
    "b_ub = np.array([200 * 40, 120 * 20])\n",
    "\n",
    "# 等式约束矩阵和右侧常数\n",
    "# A_eq = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
    "\n",
    "A_eq = np.array([[1, 0, 0], [0, 1, 1]])\n",
    "\n",
    "b_eq = np.array([1000, 1600])\n",
    "\n",
    "# 变量取值范围\n",
    "# x_bounds = [(0, None), (0, None), (0, None), (0, None)]\n",
    "x_bounds = [(0, None), (0, None), (0, None)]\n",
    "\n",
    "\n",
    "# 使用线性规划求解\n",
    "result = linprog(c, A_ub=A, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=x_bounds, method='highs')\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 输出结果\n",
    "print(\"最小总成本:\", result.fun)\n",
    "print(\"甲饮料厂生产A饮料:\", result.x[0], \"t\")\n",
    "print(\"甲饮料厂生产B饮料:\", result.x[1], \"t\")\n",
    "# print(\"乙饮料厂生产A饮料:\", result.x[2], \"t\")\n",
    "print(\"乙饮料厂生产B饮料:\", result.x[2], \"t\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加约束"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加变量约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
      "        success: True\n",
      "         status: 0\n",
      "            fun: 2610000.0\n",
      "              x: [ 0.000e+00  1.600e+03  1.000e+03]\n",
      "            nit: 0\n",
      "          lower:  residual: [ 0.000e+00  1.600e+03  7.000e+02]\n",
      "                 marginals: [ 1.500e+02  0.000e+00  0.000e+00]\n",
      "          upper:  residual: [       inf        inf        inf]\n",
      "                 marginals: [ 0.000e+00  0.000e+00  0.000e+00]\n",
      "          eqlin:  residual: [ 0.000e+00  0.000e+00]\n",
      "                 marginals: [ 8.500e+02  1.100e+03]\n",
      "        ineqlin:  residual: [ 1.600e+03  4.000e+02]\n",
      "                 marginals: [-0.000e+00 -0.000e+00]\n",
      " mip_node_count: 0\n",
      " mip_dual_bound: 0.0\n",
      "        mip_gap: 0.0\n",
      "最小总成本: 2610000.0\n",
      "甲饮料厂生产A饮料: 0.0 t\n",
      "甲饮料厂生产B饮料: 1600.0 t\n",
      "乙饮料厂生产A饮料: 1000.0 t\n"
     ]
    }
   ],
   "source": [
    "# 此处去掉 x_4，并添加变量约束 x_3 >= 300\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# 目标函数系数\n",
    "# c = np.array([1000, 1100, 850, 1000])\n",
    "\n",
    "c = np.array([1000, 1100, 850])\n",
    "\n",
    "\n",
    "# 不等式约束矩阵和右侧常数\n",
    "# A = np.array([\n",
    "#     [5, 4, 0, 0],\n",
    "#     [0, 0, 2, 5]\n",
    "# ])\n",
    "\n",
    "A = np.array([\n",
    "    [5, 4, 0],\n",
    "    [0, 0, 2],\n",
    "])\n",
    "\n",
    "b_ub = np.array([200 * 40, 120 * 20])\n",
    "\n",
    "# 等式约束矩阵和右侧常数\n",
    "# A_eq = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
    "\n",
    "A_eq = np.array([[1, 0, 1], [0, 1, 0]])\n",
    "\n",
    "b_eq = np.array([1000, 1600])\n",
    "\n",
    "# 变量取值范围\n",
    "# x_bounds = [(0, None), (0, None), (0, None), (0, None)]\n",
    "x_bounds = [(0, None), (0, None), (300, None)]\n",
    "\n",
    "\n",
    "# 使用线性规划求解\n",
    "result = linprog(c, A_ub=A, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=x_bounds, method='highs')\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 输出结果\n",
    "print(\"最小总成本:\", result.fun)\n",
    "print(\"甲饮料厂生产A饮料:\", result.x[0], \"t\")\n",
    "print(\"甲饮料厂生产B饮料:\", result.x[1], \"t\")\n",
    "print(\"乙饮料厂生产A饮料:\", result.x[2], \"t\")\n",
    "# print(\"乙饮料厂生产B饮料:\", result.x[2], \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小总成本: 2662500.0\n",
      "甲饮料厂生产A饮料: 550.0 t\n",
      "甲饮料厂生产B饮料: 1300.0 t\n",
      "乙饮料厂生产A饮料: 450.0 t\n",
      "乙饮料厂生产B饮料: 300.0 t\n"
     ]
    }
   ],
   "source": [
    "# 此处仅添加约束 x_3, x_4 >= 300\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# 目标函数系数\n",
    "c = np.array([1000, 1100, 850, 1000])\n",
    "\n",
    "# 不等式约束矩阵和右侧常数\n",
    "A = np.array([\n",
    "    [5, 4, 0, 0],\n",
    "    [0, 0, 2, 5]\n",
    "])\n",
    "b_ub = np.array([200 * 40, 120 * 20])\n",
    "\n",
    "# 等式约束矩阵和右侧常数\n",
    "A_eq = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
    "b_eq = np.array([1000, 1600])\n",
    "\n",
    "# 变量取值范围\n",
    "x_bounds = [(0, None), (0, None), (300, None), (300, None)]\n",
    "\n",
    "# 使用线性规划求解\n",
    "result = linprog(c, A_ub=A, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=x_bounds, method='highs')\n",
    "\n",
    "# 输出结果\n",
    "print(\"最小总成本:\", result.fun)\n",
    "print(\"甲饮料厂生产A饮料:\", result.x[0], \"t\")\n",
    "print(\"甲饮料厂生产B饮料:\", result.x[1], \"t\")\n",
    "print(\"乙饮料厂生产A饮料:\", result.x[2], \"t\")\n",
    "print(\"乙饮料厂生产B饮料:\", result.x[3], \"t\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本数据分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长度不超过10cm或超过15cm的金属棒的比例为: 0.05400001759859086\n",
      "金属棒长度以93%的可能性落入的最小区间是: 9.825707192456882 cm到 14.174292807543118 cm\n",
      "问题3：在显著性水平 alpha=0.05 时，这批金属棒长度的标准差是否为 1.2 cm?\n",
      "样本标准差：1.6659 cm\n",
      "卡方统计量：26.9815\n",
      "临界值：23.6848\n",
      "判断结果：拒绝\n",
      "\n",
      "问题4：在显著性水平 alpha=0.05 时，利用样本数据检验这批金属棒长度的均值是否为 12 cm?\n",
      "样本均值：12.3327 cm\n",
      "标准误差：0.3098\n",
      "z统计量：1.0737\n",
      "临界值：1.6449\n",
      "判断结果：接受\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "# 问题1\n",
    "mu = 12\n",
    "sigma = 1.2\n",
    "prob_lt_10 = stats.norm.cdf(10, mu, sigma)\n",
    "prob_gt_15 = 1 - stats.norm.cdf(15, mu, sigma)\n",
    "ratio = prob_lt_10 + prob_gt_15\n",
    "print(\"长度不超过10cm或超过15cm的金属棒的比例为:\", ratio)\n",
    "\n",
    "# 问题2\n",
    "lower_bound, upper_bound = stats.norm.interval(0.93, mu, sigma)\n",
    "print(\"金属棒长度以93%的可能性落入的最小区间是:\", lower_bound, \"cm到\", upper_bound, \"cm\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机模拟(蒙特卡洛方法)求积分（建议精度尽可能大）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维正态分布落入椭圆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31303947939486954 0.17898652036430282\n",
      "0.7572\n",
      "0.7549063820107622\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import dblquad\n",
    "from scipy.stats import multivariate_normal, pearsonr\n",
    "\n",
    "\n",
    "def random_points(num_samples, mean, cov_matrix, a: float, b: float):\n",
    "    \"\"\"随机投点法\"\"\"\n",
    "    # 投点\n",
    "    random_points = np.random.multivariate_normal(mean, cov_matrix, num_samples)\n",
    "    # 计算概率\n",
    "    probability_point = (\n",
    "        np.count_nonzero(\n",
    "            random_points[:, 0] ** 2 / (a ** 2) + random_points[:, 1] ** 2 / (b ** 2) <= 1\n",
    "        )\n",
    "        / num_samples\n",
    "    )\n",
    "    return probability_point\n",
    "\n",
    "\n",
    "def mean_estimate(num_samples: int, mean, cov_matrix, a: float, b: float) -> float:\n",
    "    \"\"\"均值估计法\"\"\"\n",
    "    uniform_samples = np.random.uniform(\n",
    "        low=[-a, -b],\n",
    "        high=[a, b],\n",
    "        size=(num_samples, 2),\n",
    "    )\n",
    "    pdf = multivariate_normal.pdf(uniform_samples, mean=mean, cov=cov_matrix)\n",
    "\n",
    "    in_domain = np.where(\n",
    "        uniform_samples[:, 0] ** 2 / (a ** 2) + uniform_samples[:, 1] ** 2 / (b ** 2) <= 1\n",
    "    )[0]\n",
    "\n",
    "    probability_mean = (4 * a * b) * np.sum(pdf[in_domain]) / num_samples\n",
    "    return probability_mean\n",
    "\n",
    "\n",
    "data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,\n",
    "          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]\n",
    "\n",
    "data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,\n",
    "          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]\n",
    "\n",
    "corr, p_corr = pearsonr(data_X, data_Y)\n",
    "print(corr, p_corr)\n",
    "\n",
    "num_samples = 10000\n",
    "mean = [0, 0]\n",
    "sigma_x = 70\n",
    "sigma_y = 50\n",
    "cov_matrix = [[sigma_x ** 2, corr * sigma_x * sigma_y],\n",
    "              [corr * sigma_x * sigma_y, sigma_y ** 2]]\n",
    "a = 110\n",
    "b = 90\n",
    "\n",
    "print(random_points(num_samples, mean, cov_matrix, a, b))\n",
    "print(mean_estimate(num_samples, mean, cov_matrix, a, b))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数估计（点估计与区间估计）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 生成两个随机变量的样本数据\n",
    "x = np.random.rand(100)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# 计算相关系数\n",
    "corr_coef, p_value = pearsonr(x, y)\n",
    "\n",
    "# 打印相关系数和p值\n",
    "print(\"相关系数:\", corr_coef)\n",
    "print(\"p值:\", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方差已知时均值的估计——z 估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.816194483483706, 26.98380551651629)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm(loc=16.4, scale=np.sqrt(5.4)).interval(confidence=0.95)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方差未知时均值的估计——t 估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# 定义样本数据\n",
    "sample = np.array([4, 3, 5, 6, 2, 4, 5, 3, 4, 5])\n",
    "\n",
    "# 计算样本均值和样本标准差\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample, ddof=1)  # 使用Bessel's correction，自由度为n-1\n",
    "\n",
    "# 设置置信水平和样本大小\n",
    "confidence_level = 0.95\n",
    "sample_size = len(sample)\n",
    "\n",
    "# 计算t分布的临界值\n",
    "t_critical = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1)\n",
    "\n",
    "# 计算置信区间的边界\n",
    "margin_of_error = t_critical * sample_std / np.sqrt(sample_size)\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "print(\"置信区间:\", confidence_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.421006952856507, 17.37899304714349)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "df = 25 - 1\n",
    "\n",
    "t_dist = t(df)\n",
    "\n",
    "t_dist.interval(confidence=0.95, loc=16.4, scale=np.sqrt(5.4/df))\n",
    "\n",
    "# t_interval = np.array([t_dist.ppf(q=0.025), t_dist.ppf(q=0.975)])\n",
    "\n",
    "# mu_interval = 16.4 + np.sqrt(5.4) * t_interval\n",
    "\n",
    "# print(f\"mu_interval = {mu_interval}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 假设检验"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 均值的假设检验"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方差已知时均值的假设检验——z 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.06260990336999409, 0.9500771431429442)\n",
      "(0.7253804519009317, 0.46821866210685026)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7253804519009317, 0.46821866210685026)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def ztest(data, mean_value, variance):\n",
    "    \"\"\"\n",
    "    基于正态统计量进行一维数据均值双侧检验（在方差已知的情况下）\n",
    "\n",
    "    参数：\n",
    "    - data: 一维数组，表示观察值\n",
    "    - mean_value: 指定的均值值\n",
    "    - variance: 已知的方差值\n",
    "\n",
    "    返回值：\n",
    "    - statistic: 均值检验的统计值\n",
    "    - p_value: 均值检验的p值\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算样本均值\n",
    "    sample_mean = np.mean(data)\n",
    "\n",
    "    # 计算样本大小\n",
    "    sample_size = len(data)\n",
    "\n",
    "    # 计算标准误差\n",
    "    standard_error = np.sqrt(variance / sample_size)\n",
    "\n",
    "    # 计算正态统计量\n",
    "    z_statistic = (sample_mean - mean_value) / standard_error\n",
    "\n",
    "    # 计算p值\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(z_statistic)))\n",
    "\n",
    "    result = (z_statistic, p_value)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,\n",
    "          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]\n",
    "\n",
    "data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,\n",
    "          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]\n",
    "\n",
    "ztest(data_X, 0, 70 ** 2)\n",
    "ztest(data_Y, 0, 50 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.073677049865272, 0.28296745092979125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.073677049865272, 0.28296745092979125)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def ztest(data, mean_value, variance):\n",
    "    \"\"\"\n",
    "    基于正态统计量进行一维数据均值双侧检验（在方差已知的情况下）\n",
    "\n",
    "    参数：\n",
    "    - data: 一维数组，表示观察值\n",
    "    - mean_value: 指定的均值值\n",
    "    - variance: 已知的方差值\n",
    "\n",
    "    返回值：\n",
    "    - statistic: 均值检验的统计值\n",
    "    - p_value: 均值检验的p值\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算样本均值\n",
    "    sample_mean = np.mean(data)\n",
    "\n",
    "    # 计算样本大小\n",
    "    sample_size = len(data)\n",
    "\n",
    "    # 计算标准误差\n",
    "    standard_error = np.sqrt(variance / sample_size)\n",
    "\n",
    "    # 计算正态统计量\n",
    "    z_statistic = (sample_mean - mean_value) / standard_error\n",
    "\n",
    "    # 计算p值\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(z_statistic)))\n",
    "\n",
    "    result = (z_statistic, p_value)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "lengths = np.array([11.10, 12.43, 12.57, 14.50, 10.84, 14.10, 11.98, 9.88, 12.05, 13.00, 14.00, 13.00, 12.09, 8.85, 14.60])\n",
    "\n",
    "ztest(lengths, 12, 1.2 ** 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方差未知时均值的假设检验——t 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X 正态性检验结果:\n",
      "统计量: 5.522304623532256\n",
      "p值: 0.06321887851423949\n",
      "data_X 单样本 t 检验结果:\n",
      "t 统计量: -0.0641967753272205\n",
      "p值: 0.9494841563760554\n",
      "data_Y 正态性检验结果:\n",
      "统计量: 0.7039336514839094\n",
      "p值: 0.7033034531595805\n",
      "data_Y 单样本 t 检验结果:\n",
      "t 统计量: 0.9009033536206252\n",
      "p值: 0.37891779962953087\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import normaltest, ttest_1samp\n",
    "\n",
    "data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,\n",
    "          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]\n",
    "\n",
    "data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,\n",
    "          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]\n",
    "\n",
    "# 对 data_X 进行正态性检验\n",
    "print(\"data_X 正态性检验结果:\")\n",
    "statistic_X, pvalue_X = normaltest(data_X)\n",
    "print(\"统计量:\", statistic_X)\n",
    "print(\"p值:\", pvalue_X)\n",
    "\n",
    "# 对 data_X 进行单样本 t 检验\n",
    "print(\"data_X 单样本 t 检验结果:\")\n",
    "tstat_X, pvalue_X = ttest_1samp(data_X, popmean=0)\n",
    "print(\"t 统计量:\", tstat_X)\n",
    "print(\"p值:\", pvalue_X)\n",
    "\n",
    "# 对 data_Y 进行正态性检验\n",
    "print(\"data_Y 正态性检验结果:\")\n",
    "statistic_Y, pvalue_Y = normaltest(data_Y)\n",
    "print(\"统计量:\", statistic_Y)\n",
    "print(\"p值:\", pvalue_Y)\n",
    "\n",
    "# 对 data_Y 进行单样本 t 检验\n",
    "print(\"data_Y 单样本 t 检验结果:\")\n",
    "tstat_Y, pvalue_Y = ttest_1samp(data_Y, popmean=0)\n",
    "print(\"t 统计量:\", tstat_Y)\n",
    "print(\"p值:\", pvalue_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 单样本 t 检验:\n",
      "t 统计量: 0.7734015096597734\n",
      "p值: 0.4521467128196962\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "def ttest_1samp_verbose(data, popmean):\n",
    "    print(\"data 单样本 t 检验:\")\n",
    "    tstat, pvalue = ttest_1samp(data, popmean=popmean)\n",
    "    print(\"t 统计量:\", tstat)\n",
    "    print(\"p值:\", pvalue)\n",
    "    \n",
    "lengths = np.array([11.10, 12.43, 12.57, 14.50, 10.84, 14.10, 11.98, 9.88, 12.05, 13.00, 14.00, 13.00, 12.09, 8.85, 14.60])\n",
    "\n",
    "ttest_1samp_verbose(lengths, 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单总体方差的假设检验——卡方检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18.072292244897962, 0.964771596966736)\n",
      "chi2_acceptance_region = (8.906516481987973, 32.85232686172969)\n",
      "variance_acceptance_region = (2695.5238931084223, 9942.633820875648)\n",
      "(12.317679199999999, 0.2567980414388543)\n",
      "chi2_acceptance_region = (8.906516481987973, 32.85232686172969)\n",
      "variance_acceptance_region = (937.3521129753749, 3457.4907105686507)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def variance_test(data, expected_variance, alpha=0.05):\n",
    "    \"\"\"\n",
    "    基于卡方分布统计量进行一维数据方差双侧检验\n",
    "\n",
    "    参数：\n",
    "    - data: 一维数组，表示观察值\n",
    "    - variance_value: 指定的方差值\n",
    "\n",
    "    返回值：\n",
    "    - statistic: 方差检验的统计值\n",
    "    - p_value: 方差检验的p值\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算样本方差\n",
    "    sample_variance = np.var(data, ddof=1)\n",
    "\n",
    "    # 计算样本大小\n",
    "    sample_size = len(data)\n",
    "    \n",
    "    # 计算自由度\n",
    "    df = sample_size - 1\n",
    "\n",
    "    # 计算卡方统计量\n",
    "    chi2_statistic = df * sample_variance / expected_variance\n",
    "\n",
    "\n",
    "    # 计算p值\n",
    "    if chi2_statistic > df:\n",
    "        prob_extreme = 1 - chi2.cdf(np.abs(chi2_statistic), df)\n",
    "    else:\n",
    "        prob_extreme = chi2.cdf(np.abs(chi2_statistic), df)\n",
    "    \n",
    "    p_value = 2 * prob_extreme\n",
    "\n",
    "    result = (chi2_statistic, p_value)\n",
    "    print(result)\n",
    "    \n",
    "    # 计算样本均值\n",
    "    sample_mean = np.mean(data)\n",
    "    # 计算样本标准差\n",
    "    sample_sigma = np.std(data, ddof=1)\n",
    "    \n",
    "    # acceptance_region = chi2.interval(confidence=1-alpha, df=df, loc=sample_mean, scale=sample_sigma)\n",
    "    \n",
    "    chi2_acceptance_region = chi2.interval(confidence=1-alpha, df=df)\n",
    "    variance_acceptance_region = (df * sample_variance / chi2_acceptance_region[1], df * sample_variance / chi2_acceptance_region[0])\n",
    "    \n",
    "    # print(f\"acceptance_region: {acceptance_region}\")\n",
    "    print(f\"chi2_acceptance_region = {chi2_acceptance_region}\")\n",
    "    print(f\"variance_acceptance_region = {variance_acceptance_region}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "data_X = [-6.3, -71.6, 65.6, -79.2, -49.7, -81.9, 74.6, -47.6, -120.8, 56.9,\n",
    "          100.9, 47, 9.7, -60.1, -52.7, 86, 80.6, -42.6, 56.4, 15.2]\n",
    "\n",
    "data_Y = [28.9, 1.6, 61.7, -68, -41.3, -30.5, 87, 17.3, -17.8, 1.2,\n",
    "          -12.6, 39.1, 85, 32.7, 28.1, -9.3, -4.5, 5.1, -32, -9.5]\n",
    "\n",
    "\n",
    "sigma_0_X = 70\n",
    "sigma_0_Y = 50\n",
    "\n",
    "var_0_X = sigma_0_X ** 2\n",
    "var_0_Y = sigma_0_Y ** 2\n",
    "\n",
    "variance_test(data_X, var_0_X);\n",
    "variance_test(data_Y, var_0_Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26.981453703703703, 0.03872156413704042)\n",
      "chi2_acceptance_region = (5.628726103039734, 26.11894804503737)\n",
      "variance_acceptance_region = (1.487551997359844, 6.902679686679197)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26.981453703703703, 0.03872156413704042)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def variance_test(data, expected_variance, alpha=0.05):\n",
    "    \"\"\"\n",
    "    基于卡方分布统计量进行一维数据方差双侧检验\n",
    "\n",
    "    参数：\n",
    "    - data: 一维数组，表示观察值\n",
    "    - variance_value: 指定的方差值\n",
    "\n",
    "    返回值：\n",
    "    - statistic: 方差检验的统计值\n",
    "    - p_value: 方差检验的p值\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算样本方差\n",
    "    sample_variance = np.var(data, ddof=1)\n",
    "\n",
    "    # 计算样本大小\n",
    "    sample_size = len(data)\n",
    "    \n",
    "    # 计算自由度\n",
    "    df = sample_size - 1\n",
    "\n",
    "    # 计算卡方统计量\n",
    "    chi2_statistic = df * sample_variance / expected_variance\n",
    "\n",
    "\n",
    "    # 计算p值\n",
    "    if chi2_statistic > df:\n",
    "        prob_extreme = 1 - chi2.cdf(np.abs(chi2_statistic), df)\n",
    "    else:\n",
    "        prob_extreme = chi2.cdf(np.abs(chi2_statistic), df)\n",
    "    \n",
    "    p_value = 2 * prob_extreme\n",
    "\n",
    "    result = (chi2_statistic, p_value)\n",
    "    print(result)\n",
    "    \n",
    "    # 计算样本均值\n",
    "    sample_mean = np.mean(data)\n",
    "    # 计算样本标准差\n",
    "    sample_sigma = np.std(data, ddof=1)\n",
    "    \n",
    "    # acceptance_region = chi2.interval(confidence=1-alpha, df=df, loc=sample_mean, scale=sample_sigma)\n",
    "    \n",
    "    chi2_acceptance_region = chi2.interval(confidence=1-alpha, df=df)\n",
    "    variance_acceptance_region = (df * sample_variance / chi2_acceptance_region[1], df * sample_variance / chi2_acceptance_region[0])\n",
    "    \n",
    "    # print(f\"acceptance_region: {acceptance_region}\")\n",
    "    print(f\"chi2_acceptance_region = {chi2_acceptance_region}\")\n",
    "    print(f\"variance_acceptance_region = {variance_acceptance_region}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "lengths = np.array([11.10, 12.43, 12.57, 14.50, 10.84, 14.10, 11.98, 9.88, 12.05, 13.00, 14.00, 13.00, 12.09, 8.85, 14.60])\n",
    "\n",
    "variance_test(lengths, 1.2 ** 2, alpha=0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迷之检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卡方检验结果:\n",
      "卡方统计量: 0.5555555555555556\n",
      "p值: 0.7574651283969664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def variance_test(data, alpha):\n",
    "    \"\"\"\n",
    "    基于卡方分布统计量进行方差检验\n",
    "\n",
    "    参数：\n",
    "    - data: 包含多个样本的二维数组，每一行是一个样本的观察值\n",
    "    - alpha: 显著性水平\n",
    "\n",
    "    返回值：\n",
    "    - result: 布尔值，True表示拒绝原假设，即样本的方差存在显著差异；False表示无法拒绝原假设\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算总体均值\n",
    "    grand_mean = np.mean(data)\n",
    "\n",
    "    # 计算每个样本的观察值和样本大小\n",
    "    sample_means = np.mean(data, axis=1)\n",
    "    sample_sizes = data.shape[1]\n",
    "\n",
    "    # 计算每个样本的平方和\n",
    "    ss_total = np.sum((data - grand_mean)**2)\n",
    "\n",
    "    # 计算组内平方和\n",
    "    ss_within = np.sum((data - sample_means[:, np.newaxis])**2)\n",
    "\n",
    "    # 计算组间平方和\n",
    "    ss_between = ss_total - ss_within\n",
    "\n",
    "    # 计算自由度\n",
    "    df_between = data.shape[0] - 1\n",
    "    df_within = data.shape[0] * (sample_sizes - 1)\n",
    "\n",
    "    # 计算卡方统计量\n",
    "    chi2_statistic = (ss_between / df_between) / (ss_within / df_within)\n",
    "\n",
    "    # 计算临界值\n",
    "    critical_value = chi2.ppf(1 - alpha, df_between)\n",
    "\n",
    "    # 判断是否拒绝原假设\n",
    "    result = chi2_statistic > critical_value\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
