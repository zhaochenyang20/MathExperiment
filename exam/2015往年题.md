# 1

```py
import numpy as np

# 创建一个 5x5 的零矩阵
matrix = np.zeros((50, 50))

# 使用 diag 函数设置主对角线和次对角线元素
np.fill_diagonal(matrix, 2)
np.fill_diagonal(matrix[1:], 1)
np.fill_diagonal(matrix[:, 1:], 1)


np.linalg.cond(matrix, 2)

import numpy as np

def split_matrix(A):
    n = A.shape[0]  # 方阵的维度
    D = np.diag(np.diag(A))  # 对角矩阵
    L = -np.tril(A, k=-1)  # 严格下三角矩阵
    U = -np.triu(A, k=1)  # 严格上三角矩阵
    return D, L, U

def spectral_radius(matrix):
    eigenvalues = np.linalg.eigvals(matrix)
    radius = np.max(np.abs(eigenvalues))
    return radius

D, L, U = split_matrix(matrix)
inv_D_minus_L = np.linalg.inv(D - L)
step_matrix = inv_D_minus_L @ U
print(np.linalg.cond(matrix, 2))
print(spectral_radius(step_matrix))


def gauss_seidel(A, x0, b, error=1e-6):
    D, L, U = split_matrix(A)
    inv_D_minus_L = np.linalg.inv(D - L)
    k = 0
    xk = x0
    while True:
        k += 1
        xk_1 = inv_D_minus_L @ (U @ xk + b)
        step = np.linalg.norm(xk - xk_1, np.inf)
        xk = xk_1
        # print("--------------------")
        # print(f"迭代次数：{k}")
        # print(f"迭代结果：{xk}")
        # print(f"step {step}")
        if k == 10:
            return xk_1, k
        if step < error:
            return xk_1, k


b = np.array([1] * 50)

x0 = np.array([0] * 50)

x_10, k = gauss_seidel(matrix, x0, b)
print(x_10[4], x_10[17], x_10[26])

np.linalg.norm(matrix @ x_10 - b, 1)
```

```python
1053.4789912001163
0.9962102548359668
0.3281543254852295 0.24931016832124442 0.2500069297819607
Out[3]: 0.08947035611346144
```

# 2

## 2.1

```python
import numpy as np
from scipy.integrate import odeint

def dy_dx(input_list, x):
    y = input_list[0]
    dy_dx = y ** 3 -np.exp(y) + x - 1
    return dy_dx

# 初始条件
y_a = [1.6]

# 自变量范围
x = np.linspace(1, 2, 10000)

# 求解微分方程
y = odeint(dy_dx, y_a, x)

# 输出结果
print((y[-1]))
```

```python
[0.577319]
```

## 2.2 改进欧拉公式

```python
import numpy as np

def dy_dx(y, x):
    return y ** 3 - np.exp(y) + x - 1

# 初始条件
y = 1.6
x = 1
h = 0.2
x_target = 2

# 使用改进欧拉公式进行数值积分
# 对于改进欧拉公式在 x = 1 算出 y(1.2)，所以迭代到 1.8 就该停下，尤其小心 python 浮点数的精度
while x < x_target - 1e-6:
    print(x)
    y_temp = y + h * dy_dx(y, x)
    y = y + h / 2 * (dy_dx(y, x) + dy_dx(y_temp, x + h))
    print(y)
    x += h
```

```py
import numpy as np
import matplotlib.pyplot as plt

x0 = 1.6
h = 0.2
x = np.arange(1, 2+ 0.5 * h, h)
n = len(x)

def ode2(y, t):
    return y**3 - np.exp(y) + t - 1

y = np.zeros(n)
y[0] = x0
for k in range(1, n):
    yy = y[k-1] + h * ode2(y[k-1], x[k-1])
    f1 = ode2(y[k-1], x[k-1])
    f2 = ode2(yy, x[k])
    y[k] = y[k-1] + h * (f1 + f2) / 2

print(x[-1], y[-1])
```

# 3

非常基本，简单的规划即可。

# 4

```matlab
% 定义目标函数
fun = @(x) 2 * x(1)^2 + 2 * x(2)^2 + 3 * x(1) * x(2) - 4 * x(1) - 8 * x(2);

% 定义初始值
x0 = [0, 0];

% 使用 BFGS 方法进行搜索
options = optimoptions('fminunc', 'Algorithm', 'quasi-newton');

% 调用 fminunc 函数求解
[x, fval] = fminunc(fun, x0, options);

% 输出结果
disp(x);
```

```python
def f(x1, x2):
    f = 2 * x1**2 + 2 * x2**2 + 3 * x1 * x2 - 4 * x1 - 8 * x2

用 fminunc 命令计算上述函数的局部极小值，初始值为 (0, 0)，搜索方法为 BFGS，给出 Matlab 代码，得到默认精度下近似解 x*

搜索方法改为最速下降法，自变量与函数值的精度都设定为 10**(-2)。此时的近似解 x* 为？请给出 MatLab 代码。
```

# 5

## 5.1

